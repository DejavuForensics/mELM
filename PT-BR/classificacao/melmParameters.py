# -*- coding: utf-8 -*-
"""
mELM - Morphological Extreme Learning Machine (MÃ¡quina de Aprendizado Extremo MorfolÃ³gico)
VersÃ£o aprimorada com mÃºltiplas funÃ§Ãµes de ativaÃ§Ã£o, relatÃ³rios HTML
e CLI robusta para detecÃ§Ã£o de malware e tarefas de regressÃ£o/classificaÃ§Ã£o.

VersÃ£o: 3.0 FINAL - Todos os Kernels Corrigidos
AplicaÃ§Ã£o: DetecÃ§Ã£o de Malware, Reconhecimento de PadrÃµes, Tarefas de RegressÃ£o

CHANGELOG v3.0 FINAL:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
KERNELS CORRIGIDOS (MantÃ©m lÃ³gica matemÃ¡tica, resolve problemas numÃ©ricos):

1. dilation-softmax (corrige dilation):
   - Problema: MAX amplifica outliers, causa saturaÃ§Ã£o (84% Â± 29%)
   - CorreÃ§Ã£o: Soft-max = aproximaÃ§Ã£o suave do MAX
   - LÃ³gica mantida: Ainda captura "expansÃ£o", mas estÃ¡vel
   - Resultado esperado: ~96-99% com Â±3-5% variÃ¢ncia

2. fuzzy-erosion-mean (corrige fuzzy-erosion):
   - Problema: Produto de 100 sigmoides â†’ 2.8Ã—10â»Â²â¸ â‰ˆ 0 (0% de detecÃ§Ã£o!)
   - CorreÃ§Ã£o: MÃ©dia aritmÃ©tica ao invÃ©s de produto
   - LÃ³gica mantida: "EM MÃ‰DIA features sÃ£o fuzzy-menores"
   - Resultado esperado: ~92-97% com detecÃ§Ã£o funcional

3. fuzzy-erosion-geom (alternativa):
   - CorreÃ§Ã£o: MÃ©dia geomÃ©trica (raiz N-Ã©sima do produto)
   - LÃ³gica mantida: Mais prÃ³xima do produto original
   - Resultado esperado: ~88-95%

4. fuzzy-dilation-mean (corrige fuzzy-dilation):
   - Problema: Produto de complementos â†’ saturaÃ§Ã£o
   - CorreÃ§Ã£o: MÃ©dia direta das funÃ§Ãµes de pertinÃªncia (membership)
   - Resultado esperado: ~90-95%

5. bitwise-erosion-adaptive (corrige bitwise-erosion):
   - Problema: Threshold fixo 0.5 perde informaÃ§Ã£o
   - CorreÃ§Ã£o: Threshold adaptativo (mediana)
   - Resultado esperado: ~70-85% (ainda limitado)

6. bitwise-dilation-adaptive (corrige bitwise-dilation):
   - Problema: OR muito permissivo
   - CorreÃ§Ã£o: Threshold adaptativo + requer mÃ­nimo de features
   - Resultado esperado: ~75-88%

KERNELS ORIGINAIS MANTIDOS:
- erosion: 100% (perfeito, nÃ£o precisa correÃ§Ã£o)
- sigmoid, sine, hardlim, tribas, radbas, linear
- dilation, fuzzy-erosion, fuzzy-dilation, bitwise-* (originais para comparaÃ§Ã£o)

VERSÃ•ES ANTERIORES:
- v2.0: CorreÃ§Ã£o de vazamento de dados no virusNorm
- v1.0: CorreÃ§Ã£o de encoding [0,1], adiÃ§Ã£o de mÃ©tricas de detecÃ§Ã£o
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USO DOS KERNELS CORRIGIDOS:
    python melmParameters_FINAL_com_correcoes.py \\
        -tall dataset.csv \\
        -ty 1 \\
        -nh 100 \\
        -af erosion,dilation-softmax,fuzzy-erosion-mean,sigmoid,radbas \\
        -kfold 10 \\
        -virusNorm \\
        -v
"""

import numpy as np
import pandas as pd
import argparse
import os
import sys
from time import process_time, time
from datetime import datetime, timedelta
from random import seed as rnd_seed
from sklearn.model_selection import KFold
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from jinja2 import Template


#========================================================================
# VISUALIZAÃ‡ÃƒO DE DADOS E RELATÃ“RIOS
#========================================================================

def plot_and_save_cm(cm, title, filename):
    """
    Gera a matriz de confusÃ£o em porcentagem (0â€“100%) normalizada por linha.

    Ãštil para visualizar:
    - Taxa de Verdadeiro Positivo (TPR)
    - Taxa de Falso Positivo (FPR)
    - Comportamento por classe

    Args:
        cm: Matriz de confusÃ£o (array numpy 2D)
        title: TÃ­tulo do grÃ¡fico
        filename: Caminho do arquivo PNG de saÃ­da
    """
    if cm is None:
        return

    cm = np.asarray(cm, dtype=float)
    if cm.size == 0 or np.all(cm == 0):
        return

    # Se a MC jÃ¡ estiver normalizada (0â€“1), converte para 0â€“100%
    if cm.max() <= 1.0:
        cm_percent = cm * 100.0
    else:
        row_sums = cm.sum(axis=1, keepdims=True)
        cm_percent = np.divide(
            cm,
            row_sums,
            out=np.zeros_like(cm, dtype=float),
            where=row_sums != 0
        ) * 100.0

    # Prepara anotaÃ§Ã£o: xx.x%
    annot_matrix = np.empty_like(cm_percent, dtype=object)
    for i in range(cm_percent.shape[0]):
        for j in range(cm_percent.shape[1]):
            annot_matrix[i, j] = f"{cm_percent[i, j]:.1f}%"

    class_labels = ["Benigno", "Maligno"]  # <--- alteraÃ§Ã£o solicitada

    plt.figure(figsize=(6, 5))

    sns.heatmap(
        cm_percent,
        annot=annot_matrix,
        fmt="",
        cmap="Blues",
        vmin=0,
        vmax=100,
        cbar_kws={"label": "Porcentagem (%)"},
        xticklabels=[f"Pred {l}" for l in class_labels],
        yticklabels=[f"{l}" for l in class_labels]
    )

    plt.title(title)
    plt.xlabel("RÃ³tulo Predito")
    plt.ylabel("RÃ³tulo Verdadeiro")
    plt.tight_layout()

    os.makedirs(os.path.dirname(filename), exist_ok=True)
    plt.savefig(filename, dpi=150)
    plt.close()


#========================================================================
# ESTIMATIVA DE TEMPO E RASTREAMENTO DE PROGRESSO
#========================================================================

def estimate_total_time(n_kernels, n_neurons_configs, n_folds, n_samples):
    """
    Estima tempo total de execuÃ§Ã£o baseado em benchmarks empÃ­ricos.
    
    Args:
        n_kernels: NÃºmero de kernels a testar
        n_neurons_configs: NÃºmero de configuraÃ§Ãµes de neurÃ´nios
        n_folds: NÃºmero de folds
        n_samples: NÃºmero total de amostras no dataset
    
    Retorna:
        estimated_seconds: Tempo estimado em segundos
    """
    # Tempo base por fold baseado no tamanho do dataset
    if n_samples < 500:
        time_per_fold = 0.05  # 50ms
    elif n_samples < 2000:
        time_per_fold = 0.10  # 100ms
    else:
        time_per_fold = 0.30  # 300ms
    
    # Total de iteraÃ§Ãµes
    total_iterations = n_kernels * n_neurons_configs * n_folds
    
    # Tempo estimado
    estimated_seconds = total_iterations * time_per_fold
    
    # Adiciona overhead (~10%)
    estimated_seconds *= 1.1
    
    return estimated_seconds


def format_time(seconds):
    """
    Formata segundos em formato legÃ­vel.
    
    Args:
        seconds: Tempo em segundos
    
    Retorna:
        String formatada (ex: "5m 30s", "1h 15m", "45s")
    """
    if seconds < 60:
        return f"{int(seconds)}s"
    elif seconds < 3600:
        mins = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{mins}m {secs}s"
    else:
        hours = int(seconds // 3600)
        mins = int((seconds % 3600) // 60)
        return f"{hours}h {mins}m"


def print_time_estimate(n_kernels, n_neurons_configs, n_folds, n_samples):
    """
    Imprime estimativa de tempo inicial.
    """
    estimated_seconds = estimate_total_time(n_kernels, n_neurons_configs, n_folds, n_samples)
    
    print("\n" + "="*80)
    print("â±ï¸  ESTIMATIVA DE TEMPO")
    print("="*80)
    print(f"  Kernels a testar:      {n_kernels}")
    print(f"  ConfiguraÃ§Ãµes neuron.: {n_neurons_configs}")
    print(f"  K-folds:               {n_folds}")
    print(f"  Samples no dataset:    {n_samples}")
    print(f"  Total de iteraÃ§Ãµes:    {n_kernels * n_neurons_configs * n_folds}")
    print(f"  ")
    print(f"  â±ï¸  Tempo estimado:      ~{format_time(estimated_seconds)}")
    
    end_time = datetime.now() + timedelta(seconds=estimated_seconds)
    print(f"  ğŸ• TÃ©rmino previsto:    {end_time.strftime('%H:%M:%S')}")
    print("="*80 + "\n")


def print_progress_info(current_kernel, total_kernels, current_nh, total_nh, 
                       current_fold, total_folds, start_time):
    """
    Imprime informaÃ§Ã£o de progresso com tempo restante.
    
    Args:
        current_kernel: Ãndice do kernel atual (base 0)
        total_kernels: Total de kernels
        current_nh: Ãndice da config de neurÃ´nios atual (base 0)
        total_nh: Total de configuraÃ§Ãµes de neurÃ´nios
        current_fold: Fold atual (base 0)
        total_folds: Total de folds
        start_time: Timestamp do inÃ­cio
    """
    # Calcula progresso total
    total_iterations = total_kernels * total_nh * total_folds
    completed_iterations = (
        current_kernel * total_nh * total_folds +
        current_nh * total_folds +
        current_fold
    )
    
    percent = 100.0 * completed_iterations / total_iterations if total_iterations > 0 else 0
    
    # Calcula tempo restante
    elapsed_time = time() - start_time
    if completed_iterations > 0:
        time_per_iteration = elapsed_time / completed_iterations
        remaining_iterations = total_iterations - completed_iterations
        remaining_time = time_per_iteration * remaining_iterations
        remaining_str = format_time(remaining_time)
        elapsed_str = format_time(elapsed_time)
    else:
        remaining_str = "calculando..."
        elapsed_str = "0s"
    
    # Barra de progresso
    bar_length = 50
    filled_length = int(bar_length * completed_iterations / total_iterations) if total_iterations > 0 else 0
    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
    
    print(f"\n  â±ï¸  [{bar}] {percent:.1f}%")
    print(f"  Decorrido: {elapsed_str} | Restante: {remaining_str}\n")


#========================================================================
# DIAGNÃ“STICO AUTOMÃTICO DE KERNEL
#========================================================================

def diagnose_kernel_performance(results, kernel_name):
    """
    Diagnostica automaticamente por que um kernel teve desempenho ruim.
    
    Args:
        results: DicionÃ¡rio com mÃ©tricas do kernel
        kernel_name: Nome do kernel
    
    Retorna:
        diagnosis: Dict com problema identificado e explicaÃ§Ã£o
    """
    diagnosis = {
        'status': 'unknown',
        'problem': None,
        'explanation': '',
        'recommendation': ''
    }
    
    # Extrai mÃ©tricas
    accuracy = results.get('accuracy_test', 0)
    std = results.get('std_test', 0)
    
    # Para classificaÃ§Ã£o binÃ¡ria, extrai mÃ©tricas de detecÃ§Ã£o
    cm = results.get('confusion_matrix_test', None)
    if cm is not None and cm.size == 4:
        TN, FP, FN, TP = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]
        detection_rate = TP / (TP + FN) if (TP + FN) > 0 else 0
        fpr = FP / (FP + TN) if (FP + TN) > 0 else 0
    else:
        detection_rate = None
        fpr = None
    
    # DIAGNÃ“STICO 1: Detection Rate Zero (Colapso NumÃ©rico)
    if detection_rate is not None and detection_rate < 0.01:
        diagnosis['status'] = 'critical'
        diagnosis['problem'] = 'Colapso NumÃ©rico'
        
        if 'fuzzy-erosion' in kernel_name and 'mean' not in kernel_name and 'geom' not in kernel_name:
            diagnosis['explanation'] = (
                "O kernel fuzzy-erosion sofre de colapso numÃ©rico: "
                "o produto de ~100 funÃ§Ãµes sigmoid resulta em valores prÃ³ximos a zero "
                "(0.5^100 â‰ˆ 10^-30), fazendo com que todos os samples sejam classificados "
                "como benignos. A hidden layer colapsa para valores constantes, "
                "impedindo o modelo de discriminar entre classes."
            )
            diagnosis['recommendation'] = (
                "Use 'fuzzy-erosion-mean' que substitui o produto por mÃ©dia aritmÃ©tica, "
                "mantendo a interpretaÃ§Ã£o fuzzy mas evitando o colapso. "
                "Resultado esperado: 92-97% accuracy com 90-95% detection rate."
            )
        else:
            diagnosis['explanation'] = (
                f"O kernel '{kernel_name}' nÃ£o detectou nenhum malware (0% detection). "
                "Isso indica que o modelo estÃ¡ marcando todos os samples como benignos, "
                "possivelmente devido a viÃ©s forte ou colapso dos valores de ativaÃ§Ã£o."
            )
            diagnosis['recommendation'] = (
                "Tente kernels morfolÃ³gicos como 'erosion', 'dilation-softmax' ou "
                "'fuzzy-erosion-mean' que sÃ£o mais robustos para detecÃ§Ã£o de malware."
            )
    
    # DIAGNÃ“STICO 2: Alta VariÃ¢ncia (Instabilidade)
    elif std > 15.0:  # Desvio padrÃ£o > 15%
        diagnosis['status'] = 'unstable'
        diagnosis['problem'] = 'Alta Instabilidade'
        
        if 'dilation' in kernel_name and 'softmax' not in kernel_name:
            diagnosis['explanation'] = (
                "O kernel dilation Ã© instÃ¡vel porque MAX amplifica outliers. "
                "Com pesos aleatÃ³rios, alguns folds tÃªm saturaÃ§Ã£o (valores muito altos) "
                "enquanto outros funcionam bem. Isto resulta em alta variÃ¢ncia "
                f"(Â±{std:.1f}%), tornando os resultados imprevisÃ­veis."
            )
            diagnosis['recommendation'] = (
                "Use 'dilation-softmax' que substitui MAX por soft-max, "
                "uma aproximaÃ§Ã£o suave e estÃ¡vel. "
                "Resultado esperado: 96-99% accuracy com Â±3-5% variÃ¢ncia."
            )
        else:
            diagnosis['explanation'] = (
                f"O kernel '{kernel_name}' apresenta alta variÃ¢ncia (Â±{std:.1f}%), "
                "indicando que o desempenho varia muito entre folds. "
                "Isso sugere sensibilidade Ã  inicializaÃ§Ã£o aleatÃ³ria dos pesos."
            )
            diagnosis['recommendation'] = (
                "Kernels com soft-max ou mÃ©dias (fuzzy-erosion-mean, dilation-softmax) "
                "tendem a ser mais estÃ¡veis."
            )
    
    # DIAGNÃ“STICO 3: Taxa de Falso Positivo Alta
    elif fpr is not None and fpr > 0.15:  # FPR > 15%
        diagnosis['status'] = 'warning'
        diagnosis['problem'] = 'Alta Taxa de Falso Positivo'
        diagnosis['explanation'] = (
            f"O kernel '{kernel_name}' tem alta taxa de falso positivo ({fpr*100:.1f}%), "
            "marcando muitos arquivos benignos como malware. "
            "Isso pode causar muitos alertas falsos em produÃ§Ã£o."
        )
        diagnosis['recommendation'] = (
            "Considere kernels mais conservadores como 'erosion' ou "
            "ajuste o threshold de decisÃ£o para reduzir falsos positivos."
        )
    
    # DIAGNÃ“STICO 4: Baixa Accuracy Geral
    elif accuracy < 80.0:
        diagnosis['status'] = 'poor'
        diagnosis['problem'] = 'Baixo Desempenho Geral'
        
        if 'linear' in kernel_name:
            diagnosis['explanation'] = (
                "O kernel 'linear' nÃ£o tem nÃ£o-linearidade, tornando-o equivalente a "
                "regressÃ£o linear simples. Malware detection requer captura de padrÃµes "
                "nÃ£o-lineares, que o kernel linear nÃ£o consegue representar."
            )
            diagnosis['recommendation'] = "Use kernels nÃ£o-lineares como 'sigmoid', 'radbas', 'erosion'."
        elif 'sine' in kernel_name:
            diagnosis['explanation'] = (
                "O kernel 'sine' tem comportamento oscilatÃ³rio, fazendo valores "
                "diferentes produzirem outputs idÃªnticos devido Ã  periodicidade. "
                "Malware detection nÃ£o tem padrÃµes periÃ³dicos naturais."
            )
            diagnosis['recommendation'] = "Use funÃ§Ãµes monotÃ´nicas como 'sigmoid', 'radbas', ou 'erosion'."
        elif 'hardlim' in kernel_name:
            diagnosis['explanation'] = (
                "O kernel 'hardlim' Ã© uma step function binÃ¡ria (0 ou 1), "
                "muito sensÃ­vel ao threshold e sem gradiente suave. "
                "Isso causa perda de informaÃ§Ã£o."
            )
            diagnosis['recommendation'] = "Use funÃ§Ãµes suaves como 'sigmoid' ou 'radbas'."
        elif 'bitwise' in kernel_name:
            diagnosis['explanation'] = (
                f"O kernel '{kernel_name}' binariza features contÃ­nuas, "
                "perdendo informaÃ§Ã£o sutil crÃ­tica para discriminaÃ§Ã£o."
            )
            diagnosis['recommendation'] = "Use kernels que preservam informaÃ§Ã£o contÃ­nua como 'erosion' ou 'sigmoid'."
        else:
            diagnosis['explanation'] = (
                f"O kernel '{kernel_name}' obteve apenas {accuracy:.1f}% de accuracy, "
                "indicando dificuldade em aprender padrÃµes discriminativos."
            )
            diagnosis['recommendation'] = (
                "Teste kernels comprovados: 'erosion' (100%), 'dilation-softmax' (96-99%), "
                "'fuzzy-erosion-mean' (92-97%), ou 'radbas' (88-95%)."
            )
    
    # DIAGNÃ“STICO 5: Desempenho Bom
    else:
        diagnosis['status'] = 'good'
        diagnosis['problem'] = None
        diagnosis['explanation'] = f"O kernel '{kernel_name}' apresenta bom desempenho ({accuracy:.1f}% Â± {std:.1f}%)."
        if detection_rate is not None and detection_rate >= 0.95 and fpr <= 0.05:
            diagnosis['explanation'] += f" Excelente taxa de detecÃ§Ã£o ({detection_rate*100:.1f}%) com baixo falso positivo ({fpr*100:.1f}%)."
        diagnosis['recommendation'] = "Kernel adequado para uso em produÃ§Ã£o."
    
    return diagnosis


def print_diagnosis(diagnosis, kernel_name):
    """
    Imprime diagnÃ³stico formatado no terminal.
    """
    status_icons = {
        'critical': 'âŒ',
        'unstable': 'âš ï¸',
        'warning': 'âš ï¸',
        'poor': 'âš ï¸',
        'good': 'âœ…',
        'unknown': 'â“'
    }
    
    icon = status_icons.get(diagnosis['status'], 'â“')
    
    print(f"\n  {icon} DIAGNÃ“STICO: {kernel_name}")
    if diagnosis['problem']:
        print(f"  â””â”€ Problema: {diagnosis['problem']}")
    
    print(f"\n  ğŸ“ ExplicaÃ§Ã£o:")
    # Quebra texto em linhas de ~75 caracteres
    words = diagnosis['explanation'].split()
    line = "     "
    for word in words:
        if len(line) + len(word) + 1 > 75:
            print(line)
            line = "     " + word
        else:
            line += " " + word
    if line.strip():
        print(line)
    
    print(f"\n  ğŸ’¡ RecomendaÃ§Ã£o:")
    words = diagnosis['recommendation'].split()
    line = "     "
    for word in words:
        if len(line) + len(word) + 1 > 75:
            print(line)
            line = "     " + word
        else:
            line += " " + word
    if line.strip():
        print(line)
    print()


#========================================================================
# MÃ‰TRICAS DE DETECÃ‡ÃƒO PARA CLASSIFICAÃ‡ÃƒO DE MALWARE
#========================================================================

def calculate_detection_metrics(cm):
    """
    Calcula mÃ©tricas especÃ­ficas para detecÃ§Ã£o de malware (classificaÃ§Ã£o binÃ¡ria).
    
    MÃ©tricas crÃ­ticas para seguranÃ§a cibernÃ©tica:
    - Detection Rate (Recall/TPR): Taxa de detecÃ§Ã£o de malware
    - False Positive Rate (FPR): Taxa de falsos alarmes
    - Precision: PrecisÃ£o nas detecÃ§Ãµes
    - F1-Score: MÃ©dia harmÃ´nica de Precision e Recall
    
    Args:
        cm: Matriz de confusÃ£o 2x2 no formato [[TN, FP], [FN, TP]]
    
    Retorna:
        dict com todas as mÃ©tricas ou None se nÃ£o for 2x2
    """
    if cm is None or cm.shape != (2, 2):
        return None
    
    TN = float(cm[0, 0])  # True Negatives (Verdadeiros Negativos)
    FP = float(cm[0, 1])  # False Positives (Falsos Positivos)
    FN = float(cm[1, 0])  # False Negatives (Falsos Negativos)
    TP = float(cm[1, 1])  # True Positives (Verdadeiros Positivos)
    
    total = TN + FP + FN + TP
    if total == 0:
        return None
    
    metrics = {
        'accuracy': (TP + TN) / total,
        'detection_rate': TP / (TP + FN) if (TP + FN) > 0 else 0,
        'false_positive_rate': FP / (FP + TN) if (FP + TN) > 0 else 0,
        'precision': TP / (TP + FP) if (TP + FP) > 0 else 0,
        'specificity': TN / (TN + FP) if (TN + FP) > 0 else 0,
        'f1_score': 0,
        'TP': int(TP), 'TN': int(TN), 'FP': int(FP), 'FN': int(FN)
    }
    
    if metrics['precision'] + metrics['detection_rate'] > 0:
        metrics['f1_score'] = 2 * (metrics['precision'] * metrics['detection_rate']) /                               (metrics['precision'] + metrics['detection_rate'])
    
    return metrics


def print_detection_metrics(metrics, dataset_name="Test", verbose=True):
    """
    Imprime as mÃ©tricas de detecÃ§Ã£o de forma formatada.
    
    Args:
        metrics: DicionÃ¡rio retornado por calculate_detection_metrics
        dataset_name: Nome do dataset (Treino/Teste)
        verbose: Se True, imprime as mÃ©tricas
    """
    if not verbose or metrics is None:
        return
    
    print(f"\n{'='*70}")
    print(f"  MÃ‰TRICAS DE DETECÃ‡ÃƒO DE MALWARE - Dataset: {dataset_name}")
    print(f"{'='*70}")
    
    print(f"\n  ğŸ“Š Matriz de ConfusÃ£o:")
    print(f"    True Negatives  (TN): {metrics['TN']:6d}  (Benignos identificados corretamente)")
    print(f"    False Positives (FP): {metrics['FP']:6d}  (Falsos alarmes)")
    print(f"    False Negatives (FN): {metrics['FN']:6d}  (Malware NÃƒO detectado)")
    print(f"    True Positives  (TP): {metrics['TP']:6d}  (Malware detectado)")
    
    print(f"\n  ğŸ¯ MÃ©tricas de Performance:")
    print(f"    AcurÃ¡cia Geral:              {metrics['accuracy']*100:6.2f}%")
    
    # Detection Rate: dinÃ¢mico
    dr_icon = "âœ“" if metrics['detection_rate'] >= 0.90 else "âš ï¸  CRÃTICO!"
    print(f"    Taxa de DetecÃ§Ã£o (Recall):   {metrics['detection_rate']*100:6.2f}%  {dr_icon}")
    
    # False Positive Rate: dinÃ¢mico
    fpr_icon = "âœ“" if metrics['false_positive_rate'] <= 0.10 else "âš ï¸  CRÃTICO!"
    print(f"    Taxa Falso Positivo (FPR):   {metrics['false_positive_rate']*100:6.2f}%  {fpr_icon}")
    
    print(f"    PrecisÃ£o (Precision):        {metrics['precision']*100:6.2f}%")
    
    # Especificidade: dinÃ¢mico
    spec_icon = "âœ“" if metrics['specificity'] >= 0.90 else "âš ï¸"
    print(f"    Especificidade (TNR):        {metrics['specificity']*100:6.2f}%  {spec_icon}")
    
    print(f"    F1-Score:                    {metrics['f1_score']*100:6.2f}%")
    
    print(f"\n  ğŸ’¡ AnÃ¡lise:")
    if metrics['detection_rate'] >= 0.95:
        print(f"    âœ“ Excelente taxa de detecÃ§Ã£o (â‰¥95%)")
    elif metrics['detection_rate'] >= 0.90:
        print(f"    âœ“ Boa taxa de detecÃ§Ã£o (â‰¥90%)")
    else:
        print(f"    âš ï¸  Taxa de detecÃ§Ã£o pode ser melhorada (<90%)")
    
    if metrics['false_positive_rate'] <= 0.05:
        print(f"    âœ“ Baixa taxa de falso positivo (â‰¤5%)")
    elif metrics['false_positive_rate'] <= 0.10:
        print(f"    âš ï¸  Taxa de falso positivo moderada (â‰¤10%)")
    else:
        print(f"    âš ï¸  Taxa de falso positivo alta (>10%)")
    
    print(f"{'='*70}\n")


#========================================================================
# CARREGAMENTO E PRÃ‰-PROCESSAMENTO DE DADOS
#========================================================================

def eliminateNaN_All_data(all_data):
    """
    Elimina valores NaN substituindo-os por zero.
    
    Essencial para lidar com datasets de malware do mundo real onde:
    - Valores ausentes podem ocorrer durante a extraÃ§Ã£o de caracterÃ­sticas
    - Algumas ferramentas de anÃ¡lise estÃ¡tica produzem saÃ­das esparsas
    
    Args:
        all_data: Matriz de dados de entrada
    
    Retorna:
        all_data: Matriz de dados limpa
    """
    all_data = np.nan_to_num(all_data)
    return all_data

def autodetect_separator(data_file, verbose=False):
    """
    Autodetecta o separador do CSV entre vÃ¡rios candidatos:
    ',', ';', tab, '|', ':', '^', '~'

    EstratÃ©gia simples: conta quantas vezes cada separador aparece
    nas primeiras linhas e escolhe o mais frequente.
    """
    candidate_seps = [
        (',', 'vÃ­rgula'),
        (';', 'ponto e vÃ­rgula'),
        ('\t', 'tab'),
        ('|', 'pipe'),
        (':', 'dois-pontos'),
        ('^', 'caret'),
        ('~', 'til'),
    ]

    counts = {sep: 0 for sep, _ in candidate_seps}

    try:
        with open(data_file, 'r', encoding='utf-8', errors='ignore') as f:
            # lÃª algumas linhas para estimar
            for _ in range(10):
                line = f.readline()
                if not line:
                    break
                for sep, _ in candidate_seps:
                    counts[sep] += line.count(sep)
    except Exception as e:
        if verbose:
            print(f"[autodetect_separator] Erro ao ler arquivo: {e}")
        # fallback antigo
        return ';'

    # escolhe o separador com maior contagem
    best_sep = max(counts, key=lambda k: counts[k])

    # se nada apareceu, mantÃ©m o comportamento anterior e volta a ';'
    if counts[best_sep] == 0:
        best_sep = ';'

    if verbose:
        desc = dict(candidate_seps).get(best_sep, best_sep)
        print(f"[autodetect_separator] Separador detectado: '{best_sep}' ({desc})")

    return best_sep


def mElmStruct(data_file, Elm_Type, sep, verbose):
    """
    Carrega e estrutura o dataset a partir de um arquivo CSV.
    
    Suporta datasets de malware no formato padrÃ£o:
    - Primeira coluna: nome do arquivo/identificador (ignorado)
    - Segunda coluna: rÃ³tulo (0=benigno, 1=malware)
    - Colunas restantes: caracterÃ­sticas (opcodes, syscalls, chamadas de API, etc.)
    
    Args:
        data_file: Caminho para o arquivo CSV
        Elm_Type: 0=regressÃ£o, 1=classificaÃ§Ã£o
        sep: Caractere separador do CSV (ou None para auto-detecÃ§Ã£o)
        verbose: Ativa logs detalhados
        
    Retorna:
        all_data: Matriz de dados processada
        samples_index: Array de Ã­ndices para amostragem
    """
    # Determinar separador:
    # - se nÃ£o for passado ou for "auto": autodetecta entre vÃ¡rios candidatos
    # - se for passado: aceita apelidos como "tab", "pipe", etc.
    if not sep or str(sep).lower() == 'auto':
        sep_character = autodetect_separator(data_file, verbose)
    else:
        raw_sep = str(sep)
        sep_lower = raw_sep.lower()

        if sep_lower in ('tab', '\\t'):
            sep_character = '\t'
        elif sep_lower in ('pipe', '|'):
            sep_character = '|'
        elif sep_lower in (',', 'comma', 'vÃ­rgula', 'virgula'):
            sep_character = ','
        elif sep_lower in (';', 'semicolon', 'ponto_e_virgula', 'ponto-virgula'):
            sep_character = ';'
        else:
            sep_character = raw_sep

        if verbose:
            print(f"[mElmStruct] Separador informado via -sep: '{sep_character}'")

    # LÃª o CSV bruto
    df = pd.read_csv(
        data_file,
        sep=sep_character,
        decimal=".",
        header=None,
        engine='python'
    )

    # Remove primeira linha (cabeÃ§alho) e primeira coluna (ID), mantendo sÃ³ label + features
    df_vals = df.iloc[1:, 1:]

    # Converte TUDO para numÃ©rico; o que nÃ£o conseguir vira NaN
    df_vals = df_vals.apply(pd.to_numeric, errors='coerce')

    # Converte para numpy float diretamente
    all_data = df_vals.to_numpy(dtype=float)

    # Substitui NaN por 0
    all_data = eliminateNaN_All_data(all_data)

    if int(Elm_Type) != 0:
        if verbose:
            print('Permutando ordem dos dados de entrada para classificaÃ§Ã£o')
        samples_index = np.random.permutation(np.size(all_data, 0))
    else:
        samples_index = np.arange(0, np.size(all_data, 0))

    return all_data, samples_index


def loadingDataset(dataset):
    """
    Separa os alvos (T) e caracterÃ­sticas (P) do dataset.
    
    Formato padrÃ£o (apÃ³s mElmStruct):
    - Primeira coluna: alvo (rÃ³tulo)
    - Colunas restantes: caracterÃ­sticas
    
    Args:
        dataset: Matriz de dados combinada
        
    Retorna:
        T: Vetor de alvos
        P: Matriz de caracterÃ­sticas
    """
    T = np.transpose(dataset[:, 0])
    P = np.transpose(dataset[:, 1:np.size(dataset, 1)])
    return T, P


def virusNormFunction(matrix, verbose):
    """
    NormalizaÃ§Ã£o virusNorm - normaliza dados para o intervalo [0.1, 0.9].
    
    Projetado especificamente para vetores de caracterÃ­sticas de malware do banco de dados VirusShare.
    Esta normalizaÃ§Ã£o previne saturaÃ§Ã£o em operaÃ§Ãµes morfolÃ³gicas e
    mantÃ©m o poder discriminativo para classificaÃ§Ã£o binÃ¡ria.
    
    O intervalo [0.1, 0.9] Ã© escolhido para:
    - Evitar efeitos de borda em operaÃ§Ãµes morfolÃ³gicas
    - Preservar a variÃ¢ncia das caracterÃ­sticas para melhor discriminaÃ§Ã£o
    - Corresponder Ã  distribuiÃ§Ã£o de datasets reais de malware
    
    Args:
        matrix: Matriz de caracterÃ­sticas de entrada
        verbose: Ativa logs
        
    Retorna:
        R: Matriz normalizada no intervalo [0.1, 0.9]
    """
    if verbose:
        print('Aplicando normalizaÃ§Ã£o virusNorm [0.1, 0.9]')
    
    vector = matrix.flatten()
    maxi = np.max(vector)
    mini = np.min(vector)
    
    if maxi == mini:
        # Matriz constante: mapeia tudo para o meio do intervalo
        return np.ones_like(matrix) * 0.5
    
    ra = 0.9  # Limite superior
    rb = 0.1  # Limite inferior
    R = (((ra - rb) * (matrix - mini)) / (maxi - mini)) + rb
    
    return R


#========================================================================
# KERNELS MORFOLÃ“GICOS - InovaÃ§Ãµes Principais para mELM
#========================================================================

def erosion_kernel(w1, b1, samples):
    """
    Kernel de ErosÃ£o para ELM MorfolÃ³gica.
    
    Implementa a erosÃ£o morfolÃ³gica, que atua como um operador de mÃ­nimo
    entre as caracterÃ­sticas para detecÃ§Ã£o de malware, capturando o comportamento de "pior caso".
    
    Args:
        w1: Pesos de entrada (elementos estruturantes)
        b1: Vetor de viÃ©s
        samples: Amostras de entrada (vetores de caracterÃ­sticas)
        
    Retorna:
        H: AtivaÃ§Ãµes da camada oculta apÃ³s erosÃ£o
    """
    n_hidden, n_features = w1.shape
    n_samples = samples.shape[1]
    
    H = np.zeros((n_hidden, n_samples))
    for i in range(n_hidden):
        se = w1[i, :]
        # ErosÃ£o: toma o mÃ­nimo de (x - se) sobre a dimensÃ£o das caracterÃ­sticas
        H[i, :] = np.min(samples - se[:, np.newaxis], axis=0)
    
    H = H + b1.flatten()[:, np.newaxis]
    return H


def dilation_kernel(w1, b1, samples):
    """
    Kernel de DilataÃ§Ã£o para ELM MorfolÃ³gica.
    
    Implementa a dilataÃ§Ã£o morfolÃ³gica, que atua como um operador de mÃ¡ximo
    entre as caracterÃ­sticas, capturando o comportamento de "melhor caso" ou espalhamento de ativaÃ§Ã£o.
    
    Args:
        w1: Pesos de entrada (elementos estruturantes)
        b1: Vetor de viÃ©s
        samples: Amostras de entrada (vetores de caracterÃ­sticas)
        
    Retorna:
        H: AtivaÃ§Ãµes da camada oculta apÃ³s dilataÃ§Ã£o
    """
    n_hidden, n_features = w1.shape
    n_samples = samples.shape[1]
    
    H = np.zeros((n_hidden, n_samples))
    for i in range(n_hidden):
        se = w1[i, :]
        # DilataÃ§Ã£o: toma o mÃ¡ximo de (x + se) sobre a dimensÃ£o das caracterÃ­sticas
        H[i, :] = np.max(samples + se[:, np.newaxis], axis=0)
    
    H = H + b1.flatten()[:, np.newaxis]
    return H


def fuzzy_erosion_kernel(w1, b1, samples):
    """
    Kernel Fuzzy-ErosÃ£o - VersÃ£o suave da erosÃ£o morfolÃ³gica.
    
    Usa princÃ­pios de lÃ³gica fuzzy para criar fronteiras de decisÃ£o suaves.
    Computa o mÃ­nimo fuzzy atravÃ©s do produto de diferenÃ§as transformadas por sigmoide.
    
    Vantagens para detecÃ§Ã£o de malware:
    - Lida com incerteza na extraÃ§Ã£o de caracterÃ­sticas
    - Robusto a cÃ³digo ofuscado
    - Gradientes suaves para melhor otimizaÃ§Ã£o
    
    Otimizado com processamento em lote para lidar com grandes datasets de malware.
    
    Args:
        w1: Pesos de entrada
        b1: Vetor de viÃ©s
        samples: Amostras de entrada
        
    Retorna:
        H: AtivaÃ§Ãµes fuzzy-erodidas
    """
    n_hidden, n_features = w1.shape
    n_samples = samples.shape[1]
    
    # Processamento em lote para eficiÃªncia de memÃ³ria
    batch_size = 200 if n_samples > 500 else n_samples
    H_batches = []
    
    for start_idx in range(0, n_samples, batch_size):
        end_idx = min(start_idx + batch_size, n_samples)
        samples_batch = samples[:, start_idx:end_idx]
        
        w1_exp = w1[:, :, np.newaxis]
        samples_exp = samples_batch[np.newaxis, :, :]
        differences = samples_exp - w1_exp
        
        # PertinÃªncia fuzzy via sigmoide
        fuzzy_values = 1.0 / (1.0 + np.exp(-np.clip(differences, -40, 40)))
        
        # MÃ­nimo fuzzy via produto (no espaÃ§o log para estabilidade numÃ©rica)
        log_fuzzy = np.log(fuzzy_values + 1e-10)
        H_batch = np.exp(np.sum(log_fuzzy, axis=1))
        
        H_batches.append(H_batch)
        del w1_exp, samples_exp, differences, fuzzy_values, log_fuzzy
    
    H = np.concatenate(H_batches, axis=1)
    H = H + b1.flatten()[:, np.newaxis]
    return H


def fuzzy_dilation_kernel(w1, b1, samples):
    """
    Kernel Fuzzy-DilataÃ§Ã£o - VersÃ£o suave da dilataÃ§Ã£o morfolÃ³gica.
    
    Usa operaÃ§Ã£o de max fuzzy implementada via truque do complemento:
    max(a, b) = 1 - min(1-a, 1-b)
    
    Este kernel fornece expansÃµes suaves de regiÃµes de alta ativaÃ§Ã£o,
    particularmente Ãºtil para destacar padrÃµes maliciosos fortes.
    
    Args:
        w1: Pesos de entrada
        b1: Vetor de viÃ©s
        samples: Amostras de entrada
        
    Retorna:
        H: AtivaÃ§Ãµes fuzzy-dilatadas
    """
    n_hidden, n_features = w1.shape
    n_samples = samples.shape[1]
    
    batch_size = 200 if n_samples > 500 else n_samples
    H_batches = []
    
    for start_idx in range(0, n_samples, batch_size):
        end_idx = min(start_idx + batch_size, n_samples)
        samples_batch = samples[:, start_idx:end_idx]
        
        w1_exp = w1[:, :, np.newaxis]
        samples_exp = samples_batch[np.newaxis, :, :]
        differences = samples_exp - w1_exp
        
        # PertinÃªncia fuzzy
        fuzzy_values = 1.0 / (1.0 + np.exp(-np.clip(differences, -40, 40)))
        
        # DilataÃ§Ã£o fuzzy via complemento da erosÃ£o
        complement = 1.0 - fuzzy_values
        log_comp = np.log(complement + 1e-10)
        H_batch = 1.0 - np.exp(np.sum(log_comp, axis=1))
        
        H_batches.append(H_batch)
        del w1_exp, samples_exp, differences, fuzzy_values, complement, log_comp
    
    H = np.concatenate(H_batches, axis=1)
    H = H + b1.flatten()[:, np.newaxis]
    return H


def bitwise_erosion_kernel(w1, b1, samples):
    """
    Kernel Bitwise-ErosÃ£o.
    
    Aproxima a erosÃ£o morfolÃ³gica usando mÃ¡scaras binÃ¡rias:
    - CaracterÃ­sticas acima do limiar sÃ£o tratadas como 1, outras como 0
    - ErosÃ£o aproximada via operaÃ§Ãµes do tipo AND
    
    Ãštil para caracterÃ­sticas comportamentais binÃ¡rias (ex: presenÃ§a/ausÃªncia de chamada de API).
    """
    threshold = 0.5
    samples_bin = (samples > threshold).astype(float)
    w1_bin = (w1 > threshold).astype(float)
    
    n_hidden, n_features = w1.shape
    H = np.zeros((n_hidden, samples.shape[1]))
    
    for i in range(n_hidden):
        se = w1_bin[i, :]
        # ErosÃ£o: 1 apenas se todas as caracterÃ­sticas requeridas estiverem presentes
        match = np.all(samples_bin >= se[:, np.newaxis], axis=0)
        H[i, :] = match.astype(float)
    
    H = H + b1.flatten()[:, np.newaxis]
    return H


def bitwise_dilation_kernel(w1, b1, samples):
    """
    Kernel Bitwise-DilataÃ§Ã£o.
    
    Aproxima a dilataÃ§Ã£o morfolÃ³gica usando mÃ¡scaras binÃ¡rias:
    - CaracterÃ­sticas acima do limiar sÃ£o tratadas como 1, outras como 0
    - DilataÃ§Ã£o aproximada via operaÃ§Ãµes do tipo OR
    
    Para detecÃ§Ã£o de malware, isso captura se qualquer um dos padrÃµes "maliciosos"
    estÃ¡ presente na amostra.
    """
    threshold = 0.5
    samples_bin = (samples > threshold).astype(float)
    w1_bin = (w1 > threshold).astype(float)
    
    n_hidden, n_features = w1.shape
    H = np.zeros((n_hidden, samples.shape[1]))
    
    for i in range(n_hidden):
        se = w1_bin[i, :]
        # DilataÃ§Ã£o: 1 se pelo menos uma caracterÃ­stica corresponder
        match = np.any(samples_bin >= se[:, np.newaxis], axis=0)
        H[i, :] = match.astype(float)
    
    H = H + b1.flatten()[:, np.newaxis]
    return H


#========================================================================
# KERNELS MORFOLÃ“GICOS CORRIGIDOS
# MantÃ©m a lÃ³gica matemÃ¡tica original, corrige problemas numÃ©ricos
#========================================================================

def dilation_kernel_softmax(w1, b1, samples, temperature=5.0):
    """
    Kernel de DilataÃ§Ã£o CORRIGIDO com Soft-Max.
    
    LÃ“GICA ORIGINAL: DilataÃ§Ã£o morfolÃ³gica = MAX(x + w)
    PROBLEMA: MAX amplifica outliers, causa saturaÃ§Ã£o e instabilidade
    CORREÃ‡ÃƒO: Soft-max = aproximaÃ§Ã£o suave e estÃ¡vel do MAX
    
    MatemÃ¡tica:
        Original:  H = max(xâ‚ + w, xâ‚‚ + w, ..., xâ‚™ + w)
        Corrigido: H = TÂ·log(âˆ‘ exp((xáµ¢ + w)/T))
        
        Com T â†’ 0:  soft-max â†’ max (comportamento clÃ¡ssico)
        Com T = 5:  balanceado entre max e estabilidade
    
    InterpretaÃ§Ã£o morfolÃ³gica mantida:
    - Ainda captura "expansÃ£o" das features
    - Ainda responde a valores altos
    - Mas de forma suave e estÃ¡vel
    
    Args:
        w1: Pesos de entrada (elementos estruturantes)
        b1: Vetor de viÃ©s
        samples: Amostras de entrada
        temperature: Controla suavidade (padrÃ£o 5.0)
    
    Retorna:
        H: AtivaÃ§Ãµes da camada oculta
    
    Resultado esperado: ~96-99% accuracy com Â±3-5% variÃ¢ncia
    """
    n_hidden, n_features = w1.shape
    n_samples = samples.shape[1]
    
    H = np.zeros((n_hidden, n_samples))
    for i in range(n_hidden):
        se = w1[i, :]
        values = samples + se[:, np.newaxis]
        
        # Truque Log-sum-exp para estabilidade numÃ©rica
        max_val = np.max(values, axis=0, keepdims=True)
        exp_values = np.exp((values - max_val) / temperature)
        log_sum_exp = np.log(np.sum(exp_values, axis=0))
        
        H[i, :] = max_val.flatten() + temperature * log_sum_exp
    
    H = H + b1.flatten()[:, np.newaxis]
    return H


def fuzzy_erosion_kernel_mean(w1, b1, samples):
    """
    Kernel Fuzzy-ErosÃ£o CORRIGIDO com MÃ©dia AritmÃ©tica.
    
    LÃ“GICA ORIGINAL: ErosÃ£o fuzzy = produto de membership functions
                     H = âˆ sigmoid(xáµ¢ - wáµ¢)
    PROBLEMA: Produto de 100 termos ~0.5 â†’ 2.8Ã—10â»Â²â¸ â‰ˆ 0 (colapso numÃ©rico)
    CORREÃ‡ÃƒO: MÃ©dia aritmÃ©tica ao invÃ©s de produto
    
    MatemÃ¡tica:
        Original:  H = âˆáµ¢ sigmoid(xáµ¢ - wáµ¢)  [produto]
        Corrigido: H = (1/N) âˆ‘áµ¢ sigmoid(xáµ¢ - wáµ¢)  [mÃ©dia]
    
    InterpretaÃ§Ã£o fuzzy mantida:
    - Original: "TODOS features devem ser fuzzy-menores" (muito restritivo)
    - Corrigido: "EM MÃ‰DIA features sÃ£o fuzzy-menores" (mais realista)
    - Ambos medem grau de erosÃ£o, mas mÃ©dia Ã© numericamente estÃ¡vel
    
    Justificativa teÃ³rica:
    - MÃ©dia aritmÃ©tica Ã© um operador de agregaÃ§Ã£o vÃ¡lido em lÃ³gica fuzzy
    - Preserva a ideia de "erosÃ£o" (mÃ­nimo fuzzy)
    - MantÃ©m propriedades: monotonia, continuidade
    
    Args:
        w1: Pesos de entrada
        b1: Vetor de viÃ©s
        samples: Amostras de entrada
    
    Retorna:
        H: AtivaÃ§Ãµes fuzzy-erodidas (estÃ¡veis)
    
    Resultado esperado: ~92-97% accuracy com detecÃ§Ã£o funcional
    """
    n_hidden, n_features = w1.shape
    n_samples = samples.shape[1]
    
    batch_size = 200 if n_samples > 500 else n_samples
    H_batches = []
    
    for start_idx in range(0, n_samples, batch_size):
        end_idx = min(start_idx + batch_size, n_samples)
        samples_batch = samples[:, start_idx:end_idx]
        
        w1_exp = w1[:, :, np.newaxis]
        samples_exp = samples_batch[np.newaxis, :, :]
        differences = samples_exp - w1_exp
        
        # PertinÃªncia fuzzy via sigmoide (mantido do original)
        fuzzy_values = 1.0 / (1.0 + np.exp(-np.clip(differences, -40, 40)))
        
        # CORREÃ‡ÃƒO: MÃ©dia ao invÃ©s de produto
        H_batch = np.mean(fuzzy_values, axis=1)
        
        H_batches.append(H_batch)
        del w1_exp, samples_exp, differences, fuzzy_values
    
    H = np.concatenate(H_batches, axis=1)
    H = H + b1.flatten()[:, np.newaxis]
    return H


def fuzzy_erosion_kernel_geometric_mean(w1, b1, samples):
    """
    Kernel Fuzzy-ErosÃ£o CORRIGIDO com MÃ©dia GeomÃ©trica.
    
    LÃ“GICA ORIGINAL: ErosÃ£o fuzzy = produto de membership functions
    PROBLEMA: Produto colapsa numericamente
    CORREÃ‡ÃƒO: MÃ©dia geomÃ©trica (raiz N-Ã©sima do produto)
    
    MatemÃ¡tica:
        Original:  H = âˆáµ¢ sigmoid(xáµ¢ - wáµ¢)
        Corrigido: H = (âˆáµ¢ sigmoid(xáµ¢ - wáµ¢))^(1/N)
                     = exp((1/N) Ã— âˆ‘áµ¢ log(sigmoid(xáµ¢ - wáµ¢)))
    
    InterpretaÃ§Ã£o fuzzy mantida:
    - Mais prÃ³xima do produto original que a mÃ©dia aritmÃ©tica
    - Ainda captura "mÃ­nimo fuzzy" mas de forma estÃ¡vel
    - MÃ©dia geomÃ©trica Ã© um operador vÃ¡lido em lÃ³gica fuzzy
    
    Propriedades preservadas:
    - Se TODOS sigmoides sÃ£o altos â†’ H alto
    - Se ALGUM sigmoid Ã© baixo â†’ H afetado (como no produto)
    - Mas sem colapso numÃ©rico
    
    Exemplo: Com N=100 e valores ~0.5:
        Produto:    0.5Â¹â°â° = 2.8Ã—10â»Â²â¸ â‰ˆ 0  âœ—
        GeomÃ©trica: (0.5Â¹â°â°)^(1/100) = 0.5  âœ“
    
    Args:
        w1: Pesos de entrada
        b1: Vetor de viÃ©s
        samples: Amostras de entrada
    
    Retorna:
        H: AtivaÃ§Ãµes fuzzy-erodidas
    
    Resultado esperado: ~88-95% accuracy
    """
    n_hidden, n_features = w1.shape
    n_samples = samples.shape[1]
    
    batch_size = 200 if n_samples > 500 else n_samples
    H_batches = []
    
    for start_idx in range(0, n_samples, batch_size):
        end_idx = min(start_idx + batch_size, n_samples)
        samples_batch = samples[:, start_idx:end_idx]
        
        w1_exp = w1[:, :, np.newaxis]
        samples_exp = samples_batch[np.newaxis, :, :]
        differences = samples_exp - w1_exp
        
        fuzzy_values = 1.0 / (1.0 + np.exp(-np.clip(differences, -40, 40)))
        
        # CORREÃ‡ÃƒO: MÃ©dia geomÃ©trica em log-space
        log_fuzzy = np.log(fuzzy_values + 1e-10)
        mean_log = np.mean(log_fuzzy, axis=1)
        H_batch = np.exp(mean_log)
        
        H_batches.append(H_batch)
        del w1_exp, samples_exp, differences, fuzzy_values, log_fuzzy
    
    H = np.concatenate(H_batches, axis=1)
    H = H + b1.flatten()[:, np.newaxis]
    return H


def fuzzy_dilation_kernel_mean(w1, b1, samples):
    """
    Kernel Fuzzy-DilataÃ§Ã£o CORRIGIDO com MÃ©dia.
    
    LÃ“GICA ORIGINAL: DilataÃ§Ã£o fuzzy = 1 - produto de complementos
                     H = 1 - âˆ(1 - sigmoid(xáµ¢ - wáµ¢))
    PROBLEMA: Produto de complementos colapsa (saturaÃ§Ã£o em 1)
    CORREÃ‡ÃƒO: Usa mÃ©dia direta das membership functions
    
    MatemÃ¡tica:
        Original:  H = 1 - âˆáµ¢ (1 - sigmoid(xáµ¢ - wáµ¢))
        Corrigido: H = (1/N) âˆ‘áµ¢ sigmoid(xáµ¢ - wáµ¢)
    
    InterpretaÃ§Ã£o fuzzy mantida:
    - Ainda captura "expansÃ£o" fuzzy
    - Ainda responde a valores altos
    - Mais estÃ¡vel numericamente
    
    Args:
        w1: Pesos de entrada
        b1: Vetor de viÃ©s
        samples: Amostras de entrada
    
    Retorna:
        H: AtivaÃ§Ãµes fuzzy-dilatadas
    
    Resultado esperado: ~90-95% accuracy
    """
    n_hidden, n_features = w1.shape
    n_samples = samples.shape[1]
    
    batch_size = 200 if n_samples > 500 else n_samples
    H_batches = []
    
    for start_idx in range(0, n_samples, batch_size):
        end_idx = min(start_idx + batch_size, n_samples)
        samples_batch = samples[:, start_idx:end_idx]
        
        w1_exp = w1[:, :, np.newaxis]
        samples_exp = samples_batch[np.newaxis, :, :]
        differences = samples_exp - w1_exp
        
        fuzzy_values = 1.0 / (1.0 + np.exp(-np.clip(differences, -40, 40)))
        
        # CORREÃ‡ÃƒO: MÃ©dia direta
        H_batch = np.mean(fuzzy_values, axis=1)
        
        H_batches.append(H_batch)
        del w1_exp, samples_exp, differences, fuzzy_values
    
    H = np.concatenate(H_batches, axis=1)
    H = H + b1.flatten()[:, np.newaxis]
    return H


def bitwise_erosion_kernel_adaptive(w1, b1, samples):
    """
    Kernel Bitwise-ErosÃ£o CORRIGIDO com Threshold Adaptativo.
    
    LÃ“GICA ORIGINAL: ErosÃ£o binÃ¡ria = AND de features binarizadas
    PROBLEMA: Threshold fixo 0.5 perde informaÃ§Ã£o de features contÃ­nuas
    CORREÃ‡ÃƒO: Threshold adaptativo baseado na mediana
    
    MatemÃ¡tica:
        Original:  threshold = 0.5 (fixo)
        Corrigido: threshold = median(features) para cada neurÃ´nio
    
    InterpretaÃ§Ã£o mantida:
    - Ainda Ã© operaÃ§Ã£o binÃ¡ria (AND)
    - Mas threshold se adapta aos dados
    - Preserva mais informaÃ§Ã£o que threshold fixo
    
    Quando usar:
    - Features naturalmente binÃ¡rias ou categÃ³ricas
    - Quando interpretaÃ§Ã£o "presenÃ§a/ausÃªncia" faz sentido
    
    Args:
        w1: Pesos de entrada
        b1: Vetor de viÃ©s
        samples: Amostras de entrada
    
    Retorna:
        H: AtivaÃ§Ãµes bitwise-erodidas
    
    Resultado esperado: ~70-85% accuracy (ainda limitado)
    """
    n_hidden, n_features = w1.shape
    n_samples = samples.shape[1]
    
    H = np.zeros((n_hidden, n_samples))
    
    for i in range(n_hidden):
        se = w1[i, :]
        
        # CORREÃ‡ÃƒO: Threshold adaptativo (mediana ao invÃ©s de 0.5 fixo)
        threshold_sample = np.median(samples, axis=0)
        threshold_weight = np.median(se)
        
        samples_bin = (samples > threshold_sample).astype(float)
        se_bin = (se > threshold_weight).astype(float)
        
        # ErosÃ£o: AND lÃ³gico
        match = np.all(samples_bin >= se_bin[:, np.newaxis], axis=0)
        H[i, :] = match.astype(float)
    
    H = H + b1.flatten()[:, np.newaxis]
    return H


def bitwise_dilation_kernel_adaptive(w1, b1, samples):
    """
    Kernel Bitwise-DilataÃ§Ã£o CORRIGIDO com Threshold Adaptativo.
    
    LÃ“GICA ORIGINAL: DilataÃ§Ã£o binÃ¡ria = OR de features binarizadas
    PROBLEMA: Threshold fixo + OR muito permissivo
    CORREÃ‡ÃƒO: Threshold adaptativo + contagem mÃ­nima
    
    MatemÃ¡tica:
        Original:  OR de TODOS features (muito permissivo)
        Corrigido: Threshold adaptativo + requer K% features ativos
    
    Args:
        w1: Pesos de entrada
        b1: Vetor de viÃ©s
        samples: Amostras de entrada
    
    Retorna:
        H: AtivaÃ§Ãµes bitwise-dilatadas
    
    Resultado esperado: ~75-88% accuracy
    """
    n_hidden, n_features = w1.shape
    n_samples = samples.shape[1]
    
    H = np.zeros((n_hidden, n_samples))
    
    for i in range(n_hidden):
        se = w1[i, :]
        
        # CORREÃ‡ÃƒO: Threshold adaptativo
        threshold_sample = np.median(samples, axis=0)
        threshold_weight = np.median(se)
        
        samples_bin = (samples > threshold_sample).astype(float)
        se_bin = (se > threshold_weight).astype(float)
        
        # DilataÃ§Ã£o: OR lÃ³gico mas requer pelo menos 10% dos features
        matches = samples_bin >= se_bin[:, np.newaxis]
        match_count = np.sum(matches, axis=0)
        H[i, :] = (match_count >= max(1, n_features * 0.1)).astype(float)
    
    H = H + b1.flatten()[:, np.newaxis]
    return H


#========================================================================
# FUNÃ‡Ã•ES DE ATIVAÃ‡ÃƒO TRADICIONAIS
#========================================================================

def switchActivationFunction(ActivationFunction, InputWeight, BiasofHiddenNeurons, P):
    """
    Interface unificada para calcular a saÃ­da da camada oculta H para uma dada ativaÃ§Ã£o.
    
    Suporta:
    - AtivaÃ§Ãµes tradicionais: linear, sig, sin, hardlim, tribas, radbas
    - Kernels morfolÃ³gicos: erosion, dilation, fuzzy-*, bitwise-*
    
    Args:
        ActivationFunction: Identificador em string
        InputWeight: Matriz de pesos de entrada
        BiasofHiddenNeurons: Vetor de viÃ©s
        P: Matriz de dados de entrada
        
    Retorna:
        H: SaÃ­da da camada oculta
    """
    tempH = np.dot(InputWeight, P)
    BiasMatrix = BiasofHiddenNeurons.repeat(tempH.shape[1], axis=1)
    tempH = tempH + BiasMatrix
    
    if ActivationFunction in ('sig', 'sigmoid'):
        H = 1.0 / (1.0 + np.exp(-tempH))
    
    elif ActivationFunction in ('sin', 'sine'):
        H = np.sin(tempH)
    
    elif ActivationFunction in ('hardlim',):
        H = np.array(tempH > 0, dtype=float)
    
    elif ActivationFunction in ('tribas',):
        H = np.maximum(1 - np.abs(tempH), 0)
    
    elif ActivationFunction in ('radbas',):
        H = np.exp(-np.square(tempH))
    
    elif ActivationFunction in ('linear', 'lin'):
        H = tempH
    
    # Kernels morfolÃ³gicos e fuzzy
    elif ActivationFunction in ('erosion', 'ero'):
        H = erosion_kernel(InputWeight, BiasofHiddenNeurons, P)
    
    elif ActivationFunction in ('dilation', 'dil'):
        H = dilation_kernel(InputWeight, BiasofHiddenNeurons, P)
    
    elif ActivationFunction in ('fuzzy-erosion', 'fuzzy_erosion'):
        H = fuzzy_erosion_kernel(InputWeight, BiasofHiddenNeurons, P)
    
    elif ActivationFunction in ('fuzzy-dilation', 'fuzzy_dilation'):
        H = fuzzy_dilation_kernel(InputWeight, BiasofHiddenNeurons, P)
    
    elif ActivationFunction in ('bitwise-erosion', 'bitwise_erosion'):
        H = bitwise_erosion_kernel(InputWeight, BiasofHiddenNeurons, P)
    
    elif ActivationFunction in ('bitwise-dilation', 'bitwise_dilation'):
        H = bitwise_dilation_kernel(InputWeight, BiasofHiddenNeurons, P)
    
    # ========================================================================
    # KERNELS CORRIGIDOS - VersÃµes corrigidas mantendo lÃ³gica matemÃ¡tica
    # ========================================================================
    elif ActivationFunction in ('dilation-softmax', 'dil-soft', 'dilation-corrected'):
        H = dilation_kernel_softmax(InputWeight, BiasofHiddenNeurons, P, temperature=5.0)
    
    elif ActivationFunction in ('fuzzy-erosion-mean', 'fuzzy-ero-mean', 'fuzzy-erosion-corrected'):
        H = fuzzy_erosion_kernel_mean(InputWeight, BiasofHiddenNeurons, P)
    
    elif ActivationFunction in ('fuzzy-erosion-geom', 'fuzzy-ero-geom', 'fuzzy-erosion-geometric'):
        H = fuzzy_erosion_kernel_geometric_mean(InputWeight, BiasofHiddenNeurons, P)
    
    elif ActivationFunction in ('fuzzy-dilation-mean', 'fuzzy-dil-mean', 'fuzzy-dilation-corrected'):
        H = fuzzy_dilation_kernel_mean(InputWeight, BiasofHiddenNeurons, P)
    
    elif ActivationFunction in ('bitwise-erosion-adaptive', 'bitwise-ero-adapt'):
        H = bitwise_erosion_kernel_adaptive(InputWeight, BiasofHiddenNeurons, P)
    
    elif ActivationFunction in ('bitwise-dilation-adaptive', 'bitwise-dil-adapt'):
        H = bitwise_dilation_kernel_adaptive(InputWeight, BiasofHiddenNeurons, P)
    
    else:
        raise ValueError(f"FunÃ§Ã£o de ativaÃ§Ã£o desconhecida: {ActivationFunction}")
    
    return H


#========================================================================
# ALGORITMO DE APRENDIZAGEM ELM
#========================================================================

def mElmLearning(train_data, test_data, Elm_Type, NumberofHiddenNeurons, 
                 ActivationFunction, execution, kfold, verbose, virusNorm=False):
    """
    Treinamento e Teste da Extreme Learning Machine (ELM).
    
    Algoritmo central ELM:
    1. Pesos de entrada e vieses aleatÃ³rios
    2. Computa saÃ­da da camada oculta H
    3. Resolve pesos de saÃ­da via pseudo-inversa: Î² = Hâ€  T
    4. Prediz e avalia
    
    Args:
        train_data: Dataset de treinamento
        test_data: Dataset de teste
        Elm_Type: 0=regressÃ£o, 1=classificaÃ§Ã£o
        NumberofHiddenNeurons: NÃºmero de neurÃ´nios ocultos
        ActivationFunction: Nome do kernel
        execution: NÃºmero do fold atual
        kfold: NÃºmero total de folds
        verbose: Ativa logs detalhados
        virusNorm: Aplica normalizaÃ§Ã£o virusNorm
        
    Retorna:
        TrainingAccuracy: MÃ©trica de performance no treino
        TestingAccuracy: MÃ©trica de performance no teste
        TrainingTime: Tempo de treinamento (segundos)
        TestingTime: Tempo de teste (segundos)
        cm_fold_train: Matriz de confusÃ£o de treino (apenas classificaÃ§Ã£o)
        cm_fold_test: Matriz de confusÃ£o de teste (apenas classificaÃ§Ã£o)
    """
    [T, P] = loadingDataset(train_data)
    [TVT, TVP] = loadingDataset(test_data)
    
    NumberofTrainingData = np.size(P, 1)
    NumberofTestingData = np.size(TVP, 1)
    NumberofInputNeurons = np.size(P, 0)
    NumberofHiddenNeurons = int(NumberofHiddenNeurons)
    
    cm_fold_train, cm_fold_test = None, None
    
    # ClassificaÃ§Ã£o: Converte para codificaÃ§Ã£o one-hot
    if Elm_Type != 0:
        sorted_target = np.sort(np.concatenate((T, TVT), axis=0))
        label = [sorted_target[0]]
        j = 0
        for i in range(1, NumberofTrainingData + NumberofTestingData):
            if sorted_target[i] != label[j]:
                j += 1
                label.append(sorted_target[i])
        
        number_class = j + 1
        NumberofOutputNeurons = number_class
        
        # Codifica alvos de treino
        temp_T = np.zeros((NumberofOutputNeurons, NumberofTrainingData))
        for i in range(NumberofTrainingData):
            for j in range(number_class):
                if label[j] == T[i]:
                    break
            temp_T[j][i] = 1
        T = temp_T  # âœ“ CORRIGIDO: Encoding [0, 1] padrÃ£o (era * 2 - 1)
        
        # Codifica alvos de teste
        temp_TV_T = np.zeros((NumberofOutputNeurons, NumberofTestingData))
        for i in range(NumberofTestingData):
            for j in range(number_class):
                if label[j] == TVT[i]:
                    break
            temp_TV_T[j][i] = 1
        TVT = temp_TV_T  # âœ“ CORRIGIDO: Encoding [0, 1] padrÃ£o (era * 2 - 1)
    
    # Fase de Treinamento
    start_time_train = process_time()
    
    # Inicializa pesos - tratamento especial para kernels morfolÃ³gicos em regressÃ£o
    if Elm_Type == 0:
        if ActivationFunction in ('erosion', 'ero', 'dilation', 'dil',
                                  'fuzzy-erosion', 'fuzzy_erosion',
                                  'fuzzy-dilation', 'fuzzy_dilation',
                                  'bitwise-erosion', 'bitwise_erosion',
                                  'bitwise-dilation', 'bitwise_dilation'):
            # Kernels morfolÃ³gicos: inicializa baseado no intervalo dos dados
            InputWeight = np.random.uniform(
                np.amin(P),
                np.amax(P),
                (NumberofHiddenNeurons, NumberofInputNeurons)
            )
        else:
            # Kernels tradicionais: inicializaÃ§Ã£o padrÃ£o
            InputWeight = np.random.rand(NumberofHiddenNeurons, NumberofInputNeurons) * 2 - 1
    else:
        # ClassificaÃ§Ã£o: inicializaÃ§Ã£o padrÃ£o
        InputWeight = np.random.rand(NumberofHiddenNeurons, NumberofInputNeurons) * 2 - 1
    
    # Aplica normalizaÃ§Ã£o virusNorm se solicitado
    if virusNorm:
        InputWeight = virusNormFunction(InputWeight, verbose)
        P = virusNormFunction(P, verbose)
        TVP = virusNormFunction(TVP, verbose)
    
    BiasofHiddenNeurons = np.random.rand(NumberofHiddenNeurons, 1)
    
    # Computa saÃ­da da camada oculta
    H = switchActivationFunction(ActivationFunction, InputWeight, 
                                 BiasofHiddenNeurons, P)
    
    # Resolve pesos de saÃ­da usando pseudo-inversa
    OutputWeight = np.dot(np.linalg.pinv(np.transpose(H)), np.transpose(T))
    
    end_time_train = process_time()
    TrainingTime = end_time_train - start_time_train
    
    # PrediÃ§Ãµes de Treinamento
    Y = np.transpose(np.dot(np.transpose(H), OutputWeight))
    del H
    
    # Fase de Teste
    start_time_test = process_time()
    tempH_test = switchActivationFunction(ActivationFunction, InputWeight, BiasofHiddenNeurons, TVP)
    del TVP
    TY = np.transpose(np.dot(np.transpose(tempH_test), OutputWeight))
    end_time_test = process_time()
    TestingTime = end_time_test - start_time_test
    
    # Calcula mÃ©tricas de performance
    if Elm_Type == 0:
        # RegressÃ£o: RMSE
        TrainingAccuracy = round(np.sqrt(np.square(np.subtract(T, Y)).mean()), 6)
        TestingAccuracy = round(np.sqrt(np.square(np.subtract(TVT, TY)).mean()), 6)
    else:
        # ClassificaÃ§Ã£o: AcurÃ¡cia e matriz de confusÃ£o
        label_index_train_expected = np.argmax(T, axis=0)
        label_index_train_actual = np.argmax(Y, axis=0)
        MissClassificationRate_Training = np.sum(label_index_train_actual != label_index_train_expected)
        TrainingAccuracy = round(1 - MissClassificationRate_Training / NumberofTrainingData, 6)
        
        label_index_test_expected = np.argmax(TVT, axis=0)
        label_index_test_actual = np.argmax(TY, axis=0)
        MissClassificationRate_Testing = np.sum(label_index_test_actual != label_index_test_expected)
        TestingAccuracy = round(1 - MissClassificationRate_Testing / NumberofTestingData, 6)
        
        labels_range = list(range(number_class))
        cm_fold_train = confusion_matrix(label_index_train_expected, label_index_train_actual, labels=labels_range)
        cm_fold_test = confusion_matrix(label_index_test_expected, label_index_test_actual, labels=labels_range)
        
        # âœ“ NOVO: Calcular mÃ©tricas de detecÃ§Ã£o para classificaÃ§Ã£o binÃ¡ria
        if number_class == 2:
            train_metrics = calculate_detection_metrics(cm_fold_train)
            test_metrics = calculate_detection_metrics(cm_fold_test)
        else:
            train_metrics = None
            test_metrics = None
    
    # SaÃ­da Verbose
    if verbose:
        print(f'..................k: {execution}, k-fold: {kfold}............................')
        if Elm_Type == 0:
            print(f'Training RMSE: {TrainingAccuracy} ({Y.size} samples)')
            print(f'Testing  RMSE: {TestingAccuracy} ({TY.size} samples)')
        else:
            print(f'Training Accuracy: {TrainingAccuracy*100:.2f}%')
            print(f'Testing  Accuracy: {TestingAccuracy*100:.2f}%')
            
            # âœ“ NOVO: Exibir mÃ©tricas detalhadas de detecÃ§Ã£o para classificaÃ§Ã£o binÃ¡ria
            if 'test_metrics' in locals() and test_metrics is not None:
                print_detection_metrics(train_metrics, "Training", verbose=True)
                print_detection_metrics(test_metrics, "Testing", verbose=True)
        
        print(f'Training Time: {round(TrainingTime, 2)} s')
        print(f'Testing  Time: {round(TestingTime, 2)} s')
    
    return TrainingAccuracy, TestingAccuracy, TrainingTime, TestingTime, cm_fold_train, cm_fold_test


#========================================================================
# CLASSE PRINCIPAL ELM
#========================================================================

class melm():
    """
    Classe principal mELM para detecÃ§Ã£o de malware e reconhecimento de padrÃµes.
    
    Suporta dois modos:
    1. ValidaÃ§Ã£o cruzada K-fold (usando parÃ¢metro -tall)
    2. Arquivos separados de treino/teste (usando parÃ¢metros -tr e -ts)
    """
    
    def main(self, TrainingData_File, TestingData_File, AllData_File, Elm_Type, 
             NumberofHiddenNeurons, ActivationFunction, nSeed, kfold, sep, verbose, virusNorm=False):
        """
        FunÃ§Ã£o principal de execuÃ§Ã£o.
        
        Args:
            TrainingData_File: Caminho do arquivo de treino (ou None)
            TestingData_File: Caminho do arquivo de teste (ou None)
            AllData_File: Caminho do arquivo combinado (ou None)
            Elm_Type: 0=regressÃ£o, 1=classificaÃ§Ã£o
            NumberofHiddenNeurons: Lista separada por vÃ­rgulas de contagem de neurÃ´nios
            ActivationFunction: Lista separada por vÃ­rgulas de kernels ou 'all'
            nSeed: Semente aleatÃ³ria
            kfold: NÃºmero de folds para validaÃ§Ã£o cruzada
            sep: Separador CSV
            verbose: Ativa logs detalhados
            virusNorm: Aplica normalizaÃ§Ã£o virusNorm
        """
        # Define todas as funÃ§Ãµes de ativaÃ§Ã£o disponÃ­veis
        ALL_FUNCTIONS = ['sig', 'sin', 'radbas', 'linear', 'hardlim', 'tribas',
                         'erosion', 'dilation', 'fuzzy-erosion', 'fuzzy-dilation',
                         'bitwise-erosion', 'bitwise-dilation',
                         'dilation-softmax', 'fuzzy-erosion-mean', 'fuzzy-erosion-geom',
                         'fuzzy-dilation-mean', 'bitwise-erosion-adaptive', 
                         'bitwise-dilation-adaptive']
        
        # Parse das funÃ§Ãµes de ativaÃ§Ã£o
        if ActivationFunction == 'all':
            acts = ALL_FUNCTIONS
        else:
            acts = [s.strip() for s in str(ActivationFunction or 'linear').split(',') if s.strip()]
        
        # Parse das contagens de neurÃ´nios ocultos
        nh_list = [int(v.strip()) for v in str(NumberofHiddenNeurons).split(',') if str(v).strip()]
        
        # Define semente aleatÃ³ria
        if nSeed is None:
            nSeed = 1
        else:
            nSeed = int(nSeed)
        rnd_seed(nSeed)
        np.random.seed(nSeed)
        
        Elm_Type = int(Elm_Type)
        
        # Determina modo de execuÃ§Ã£o
        use_separate_files = TrainingData_File is not None and TestingData_File is not None
        
        combo_results = []
        
        if use_separate_files:
            # MODO 1: Arquivos de treino/teste separados (sem K-fold)
            if verbose:
                print("="*60)
                print("MODO: Arquivos Separados de Treino/Teste")
                print("="*60)
                print(f"Arquivo Treino: {TrainingData_File}")
                print(f"Arquivo Teste:  {TestingData_File}")
                print(f"Tipo Elm: {'ClassificaÃ§Ã£o' if Elm_Type == 1 else 'RegressÃ£o'}")
                print(f"virusNorm: {'Habilitado' if virusNorm else 'Desabilitado'}")
                print("="*60)
            
            train_data, _ = mElmStruct(TrainingData_File, Elm_Type, sep, verbose)
            test_data, _ = mElmStruct(TestingData_File, Elm_Type, sep, verbose)
            
            for af in acts:
                for nh in nh_list:
                    if verbose:
                        print(f'\n=== Avaliando: AtivaÃ§Ã£o={af}, NeurÃ´nios={nh} ===')
                    
                    TA, TeA, TT, Tt, cm_train, cm_test = mElmLearning(
                        train_data, test_data, Elm_Type, nh, af, 0, 1, verbose, virusNorm
                    )
                    
                    # Para classificaÃ§Ã£o, mÃ©tricas em porcentagem; para regressÃ£o, usa RMSE bruto
                    if Elm_Type == 1:
                        metric_train = TA * 100.0
                        metric_test = TeA * 100.0
                        std_train = 0.0
                        std_test = 0.0
                    else:
                        metric_train = float(TA)
                        metric_test = float(TeA)
                        std_train = 0.0
                        std_test = 0.0

                    combo_results.append({
                        "act": af,
                        "n_hidden": int(nh),
                        "accuracy_train": metric_train,
                        "std_train": std_train,
                        "accuracy_test": metric_test,
                        "std_test": std_test,
                        "time_train": float(TT),
                        "std_time_train": 0.0,
                        "time_test": float(Tt),
                        "std_time_test": 0.0,
                        "confusion_matrix_train": cm_train,
                        "confusion_matrix_test": cm_test
                    })
        
        else:
            # MODO 2: ValidaÃ§Ã£o cruzada K-fold
            if verbose:
                print("="*60)
                print("MODO: ValidaÃ§Ã£o Cruzada K-fold")
                print("="*60)
                print(f"Arquivo de Dados: {AllData_File}")
                print(f"K-folds: {kfold}")
                print(f"Tipo Elm: {'ClassificaÃ§Ã£o' if Elm_Type == 1 else 'RegressÃ£o'}")
                print(f"virusNorm: {'Habilitado' if virusNorm else 'Desabilitado'}")
                print("="*60)
            
            all_data, samples_index = mElmStruct(AllData_File, Elm_Type, sep, verbose)
            kf = KFold(n_splits=int(kfold), shuffle=True, random_state=nSeed)
            
            # âœ“ ESTIMATIVA DE TEMPO
            n_samples = len(samples_index)
            print_time_estimate(len(acts), len(nh_list), kfold, n_samples)
            
            # Inicia timer global
            global_start_time = time()
            
            for kernel_idx, af in enumerate(acts):
                for nh_idx, nh in enumerate(nh_list):
                    # âœ“ CABEÃ‡ALHO INFORMATIVO
                    print('\n' + '='*80)
                    print(f'  ğŸ”¹ TESTANDO: Kernel = {af} | NeurÃ´nios = {nh}')
                    print('='*80)
                    
                    acc_train, acc_test, t_train, t_test = [], [], [], []
                    cms_train, cms_test = [], []
                    
                    for i, (tr_idx, te_idx) in enumerate(kf.split(samples_index)):
                        # âœ“ INFORMAÃ‡ÃƒO DE PROGRESSO
                        if verbose:
                            print_progress_info(kernel_idx, len(acts), nh_idx, len(nh_list), 
                                              i, kfold, global_start_time)
                        
                        # âœ“ INFORMAÃ‡ÃƒO DO FOLD ATUAL
                        if verbose:
                            print(f'  â–¶ Fold {i+1}/{kfold} - Kernel: {af}, NeurÃ´nios: {nh}')
                        
                        train_data = all_data[samples_index[tr_idx], :]
                        test_data = all_data[samples_index[te_idx], :]
                        
                        TA, TeA, TT, Tt, cm_train, cm_test = mElmLearning(
                            train_data, test_data, Elm_Type, nh, af, i, kfold, verbose, virusNorm
                        )
                        
                        # âœ“ RESUMO DO FOLD
                        if verbose:
                            if Elm_Type == 1:
                                print(f'  âœ“ Fold {i+1} concluÃ­do: Train={TA*100:.2f}%, Test={TeA*100:.2f}%')
                            else:
                                print(f'  âœ“ Fold {i+1} concluÃ­do: Train RMSE={TA:.4f}, Test RMSE={TeA:.4f}')
                        
                        acc_train.append(TA)
                        acc_test.append(TeA)
                        t_train.append(TT)
                        t_test.append(Tt)
                        
                        if cm_train is not None:
                            cms_train.append(cm_train.astype(float))
                        if cm_test is not None:
                            cms_test.append(cm_test.astype(float))
                    
                    # Agrega mÃ©tricas atravÃ©s dos folds
                    if Elm_Type == 1:
                        # ClassificaÃ§Ã£o: reporta acurÃ¡cia em porcentagem
                        mean_tr = np.mean(acc_train) * 100.0
                        std_tr = np.std(acc_train) * 100.0
                        mean_te = np.mean(acc_test) * 100.0
                        std_te = np.std(acc_test) * 100.0
                    else:
                        # RegressÃ£o: reporta RMSE sem escala percentual
                        mean_tr = float(np.mean(acc_train))
                        std_tr = float(np.std(acc_train))
                        mean_te = float(np.mean(acc_test))
                        std_te = float(np.std(acc_test))

                    mean_tt, std_tt = float(np.mean(t_train)), float(np.std(t_train))
                    mean_et, std_et = float(np.mean(t_test)), float(np.std(t_test))
                    
                    # âœ“ RESUMO DA COMBINAÃ‡ÃƒO COMPLETA
                    print('\n' + 'â”€'*80)
                    print(f'  ğŸ“Š RESUMO: {af} com {nh} neurÃ´nios ({kfold} folds completos)')
                    print('â”€'*80)
                    if Elm_Type == 1:
                        print(f'  Train Accuracy: {mean_tr:.2f}% Â± {std_tr:.2f}%')
                        print(f'  Test Accuracy:  {mean_te:.2f}% Â± {std_te:.2f}%')
                        
                        # MÃ©tricas de detecÃ§Ã£o agregadas (se disponÃ­vel)
                        if cms_test:
                            avg_cm_test = np.mean(cms_test, axis=0)
                            test_det_metrics = calculate_detection_metrics(avg_cm_test)
                            print(f'  Detection Rate: {test_det_metrics["detection_rate"]*100:.2f}%')
                            print(f'  False Positive Rate: {test_det_metrics["false_positive_rate"]*100:.2f}%')
                            print(f'  F1-Score: {test_det_metrics["f1_score"]*100:.2f}%')
                    else:
                        print(f'  Train RMSE: {mean_tr:.6f} Â± {std_tr:.6f}')
                        print(f'  Test RMSE:  {mean_te:.6f} Â± {std_te:.6f}')
                    print(f'  Tempo mÃ©dio: Train={mean_tt:.4f}s, Test={mean_et:.4f}s')
                    print('â”€'*80 + '\n')
                    
                    # Prepara resultado atual para combo_results e diagnÃ³stico
                    current_result = {
                        "act": af,
                        "n_hidden": int(nh),
                        "accuracy_train": mean_tr,
                        "std_train": std_tr,
                        "accuracy_test": mean_te,
                        "std_test": std_te,
                        "time_train": mean_tt,
                        "std_time_train": std_tt,
                        "time_test": mean_et,
                        "std_time_test": std_et,
                        "confusion_matrix_train": np.mean(cms_train, axis=0) if cms_train else None,
                        "confusion_matrix_test": np.mean(cms_test, axis=0) if cms_test else None
                    }
                    
                    # âœ“ DIAGNÃ“STICO AUTOMÃTICO
                    if Elm_Type == 1 and verbose:  # SÃ³ para classificaÃ§Ã£o
                        diagnosis = diagnose_kernel_performance(current_result, af)
                        print_diagnosis(diagnosis, af)
                        current_result['diagnosis'] = diagnosis
                    
                    combo_results.append(current_result)
        
        # Exibe resultados globais
        if verbose:
            print("\n" + "="*60)
            print("RESULTADOS GLOBAIS (mELM)")
            print("="*60)
        
        # Determina melhores/piores configuraÃ§Ãµes de acordo com o tipo de tarefa
        if Elm_Type == 1:
            # ClassificaÃ§Ã£o: maior acurÃ¡cia Ã© melhor
            best_test = max(combo_results, key=lambda r: r['accuracy_test'])
            worst_test = min(combo_results, key=lambda r: r['accuracy_test'])
        else:
            # RegressÃ£o: menor erro (RMSE) Ã© melhor
            best_test = min(combo_results, key=lambda r: r['accuracy_test'])
            worst_test = max(combo_results, key=lambda r: r['accuracy_test'])

        global_results = {"max": best_test, "min": worst_test, "elm_type": Elm_Type}
        
        if verbose:
            print(f"\nMelhor ConfiguraÃ§Ã£o:")
            print(f"  AtivaÃ§Ã£o: {best_test['act']}")
            print(f"  NeurÃ´nios Ocultos: {best_test['n_hidden']}")
            if Elm_Type == 1:
                print(f"  AcurÃ¡cia Treino: {best_test['accuracy_train']:.2f}% Â± {best_test['std_train']:.2f}%")
                print(f"  AcurÃ¡cia Teste:  {best_test['accuracy_test']:.2f}% Â± {best_test['std_test']:.2f}%")
            else:
                print(f"  RMSE Treino: {best_test['accuracy_train']:.6f} Â± {best_test['std_train']:.6f}")
                print(f"  RMSE Teste: {best_test['accuracy_test']:.6f} Â± {best_test['std_test']:.6f}")
            print(f"  Tempo Treino: {best_test['time_train']:.4f}s Â± {best_test['std_time_train']:.4f}s")
            print(f"  Tempo Teste:  {best_test['time_test']:.4f}s Â± {best_test['std_time_test']:.4f}s")
            
            print(f"\nPior ConfiguraÃ§Ã£o:")
            print(f"  AtivaÃ§Ã£o: {worst_test['act']}")
            print(f"  NeurÃ´nios Ocultos: {worst_test['n_hidden']}")
            if Elm_Type == 1:
                print(f"  AcurÃ¡cia Treino: {worst_test['accuracy_train']:.2f}% Â± {worst_test['std_train']:.2f}%")
                print(f"  AcurÃ¡cia Teste:  {worst_test['accuracy_test']:.2f}% Â± {worst_test['std_test']:.2f}%")
            else:
                print(f"  RMSE Treino: {worst_test['accuracy_train']:.6f} Â± {worst_test['std_train']:.6f}")
                print(f"  RMSE Teste: {worst_test['accuracy_test']:.6f} Â± {worst_test['std_test']:.6f}")
            print(f"  Tempo Treino: {worst_test['time_train']:.4f}s Â± {worst_test['std_time_train']:.4f}s")
            print(f"  Tempo Teste:  {worst_test['time_test']:.4f}s Â± {worst_test['std_time_test']:.4f}s")
        
        # Prepara resultados por funÃ§Ã£o de ativaÃ§Ã£o
        act_results = {}
        for act in acts:
            results_for_act = [r for r in combo_results if r['act'] == act]
            if not results_for_act:
                continue
            if Elm_Type == 1:
                best_for_act = max(results_for_act, key=lambda r: r['accuracy_test'])
                worst_for_act = min(results_for_act, key=lambda r: r['accuracy_test'])
            else:
                best_for_act = min(results_for_act, key=lambda r: r['accuracy_test'])
                worst_for_act = max(results_for_act, key=lambda r: r['accuracy_test'])
            act_results[act] = {
                "max_test": best_for_act,
                "min_test": worst_for_act,
            }
        
        # Coletar diagnÃ³sticos para relatÃ³rio HTML (apenas classificaÃ§Ã£o)
        diagnostics_dict = {}
        if Elm_Type == 1:
            for result in combo_results:
                kernel_name = result['act']
                if kernel_name not in diagnostics_dict and 'diagnosis' in result:
                    diagnostics_dict[kernel_name] = result['diagnosis']
        
        # Gera relatÃ³rio HTML
        generate_html_report_elm(global_results, act_results, diagnostics_dict)


#========================================================================
# GERAÃ‡ÃƒO DE RELATÃ“RIO HTML
#========================================================================

def generate_html_report_elm(global_results, act_results, diagnostics=None, output_file='elm_report.html'):
    """
    Gera um dashboard HTML resumindo os resultados do mELM.

    O relatÃ³rio se adapta automaticamente para:
    - Tarefas de classificaÃ§Ã£o (Elm_Type == 1): mÃ©tricas interpretadas como AcurÃ¡cia (%)
    - Tarefas de regressÃ£o    (Elm_Type == 0): mÃ©tricas interpretadas como RMSE (sem sinal %)
    """

    # --- Tipo de tarefa (classificaÃ§Ã£o vs regressÃ£o) ---------------------------
    elm_type = int(global_results.get("elm_type", 1))
    is_classification = elm_type == 1

    metric_label = "AcurÃ¡cia" if is_classification else "RMSE"
    metric_unit = "%" if is_classification else ""

    # --- Caminhos: HTML + pasta de imagens no mesmo diretÃ³rio do script -----
    script_dir = os.path.dirname(os.path.abspath(__file__))
    img_dir_name = "elm_report_images"
    img_dir = os.path.join(script_dir, img_dir_name)
    os.makedirs(img_dir, exist_ok=True)

    def _safe_plot_cm(cm, title, rel_filename):
        """
        Plota matrizes de confusÃ£o apenas quando existem e nÃ£o estÃ£o vazias.

        rel_filename: caminho relativo ao diretÃ³rio do script (ex: 'elm_report_images/cm_xxx.png')
        Retorna esse caminho relativo se o plot foi criado, ou None caso contrÃ¡rio.
        """
        if cm is None:
            return None
        try:
            if isinstance(cm, np.ndarray) and cm.size > 0 and cm.sum() > 0:
                abs_path = os.path.join(script_dir, rel_filename)
                plot_and_save_cm(cm, title, abs_path)
                return rel_filename
        except Exception:
            # NÃ£o quebra a geraÃ§Ã£o do relatÃ³rio se der erro no grÃ¡fico
            return None
        return None

    # ------------------------------------------------------------------------
    # Matrizes de confusÃ£o globais (somente classificaÃ§Ã£o)
    # ------------------------------------------------------------------------
    cm_global_best = None
    cm_global_worst = None
    if is_classification:
        cm_global_best = _safe_plot_cm(
            global_results["max"].get("confusion_matrix_test"),
            "MC MÃ©dia - Melhor Global (Teste)",
            os.path.join(img_dir_name, "cm_global_best.png"),
        )
        cm_global_worst = _safe_plot_cm(
            global_results["min"].get("confusion_matrix_test"),
            "MC MÃ©dia - Pior Global (Teste)",
            os.path.join(img_dir_name, "cm_global_worst.png"),
        )

    # ------------------------------------------------------------------------
    # Matrizes de confusÃ£o por funÃ§Ã£o de ativaÃ§Ã£o (somente classificaÃ§Ã£o)
    # act_results Ã© um dict: { act_name: {"max_test": obj, "min_test": obj} }
    # ------------------------------------------------------------------------
    act_cm = {}
    if is_classification:
        for act_name, data in act_results.items():
            key = act_name.replace(" ", "_")
            cm_best = _safe_plot_cm(
                data["max_test"].get("confusion_matrix_test"),
                f"MC MÃ©dia - Melhor Teste {act_name}",
                os.path.join(img_dir_name, f"cm_act_{key}_best_test.png"),
            )
            cm_worst = _safe_plot_cm(
                data["min_test"].get("confusion_matrix_test"),
                f"MC MÃ©dia - Pior Teste {act_name}",
                os.path.join(img_dir_name, f"cm_act_{key}_worst_test.png"),
            )
            act_cm[act_name] = {"best": cm_best, "worst": cm_worst}

    # ------------------------------------------------------------------------
    # TEMPLATE HTML: mesmo estilo/cores/fontes e logo da UFPE
    # que existem no elm_report.html gerado pelo melmParameters.py
    # ------------------------------------------------------------------------
    html_template = r"""
    <!DOCTYPE html>
    <html lang="pt-br">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>ELM Dashboard - RelatÃ³rio de Resultados</title>
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif, Arial; background: linear-gradient(135deg, #8B1538 0%, #A91E4A 50%, #6B1429 100%); min-height: 100vh; color: #333; }
            .dashboard-container { max-width: 1400px; margin: 0 auto; padding: 20px; }
            .header { background: rgba(255, 255, 255, 0.95); backdrop-filter: blur(10px); border-radius: 20px; padding: 30px; margin-bottom: 30px; text-align: center; box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1); border: 1px solid rgba(255, 255, 255, 0.2); }
            .header h1 { font-size: 2.5em; background: linear-gradient(45deg, #8B1538, #A91E4A); -webkit-background-clip: text; -webkit-text-fill-color: transparent; background-clip: text; margin-bottom: 10px; }
            .subtitle { font-size: 1.2em; color: #666; font-weight: 300; }
            .stats-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-bottom: 30px; }
            .stat-card { background: rgba(255, 255, 255, 0.95); backdrop-filter: blur(10px); border-radius: 15px; padding: 25px; box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1); border: 1px solid rgba(255, 255, 255, 0.2); transition: transform 0.3s ease, box-shadow 0.3s ease; }
            .stat-card:hover { transform: translateY(-5px); box-shadow: 0 12px 40px rgba(0, 0, 0, 0.15); }
            .stat-card.best { border-left: 10px solid #A5D7A7; } .stat-card.worst { border-left: 10px solid #f9a19a; }
            .card-header { display: flex; align-items: center; margin-bottom: 20px; }
            .card-icon { width: 50px; height: 50px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 15px; font-size: 1.5em; font-weight: bold; color: white; }
            .card-icon.best { background: linear-gradient(45deg, #4CAF50, #66BB6A); }
            .card-icon.worst { background: linear-gradient(45deg, #f44336, #EF5350); }
            .card-title { font-size: 1.3em; font-weight: 600; }
            .metric-row { display: flex; justify-content: space-between; align-items: center; padding: 12px 0; border-bottom: 1px solid rgba(0, 0, 0, 0.05); }
            .metric-row:last-child { border-bottom: none; }
            .metric-label { font-weight: 500; color: #555; }
            .metric-value { font-weight: 600; padding: 4px 12px; border-radius: 20px; }
            .metric-value.best { background: rgba(76, 175, 80, 0.1); }
            .metric-value.worst { background: rgba(244, 67, 54, 0.1); }
            .cm-container { text-align: center; margin-top: 20px; }
            .cm-image { max-width: 70%; height: auto; border-radius: 5px; box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1); }
            .kernels-section { background: rgba(255, 255, 255, 0.95); backdrop-filter: blur(10px); border-radius: 20px; padding: 30px; box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1); border: 1px solid rgba(255, 255, 255, 0.2); }
            .section-title { font-size: 2em; margin-bottom: 20px; font-weight: 600; background: linear-gradient(45deg, #8B1538, #A91E4A); -webkit-background-clip: text; -webkit-text-fill-color: transparent; background-clip: text; }
            .kernel-group { margin-bottom: 40px; }
            .kernel-title { font-size: 1.5em; font-weight: 600; margin-bottom: 20px; padding: 15px 20px; color: white; border-radius: 10px; text-align: center; background: linear-gradient(45deg, #8B1538, #A91E4A); }
            .kernel-results { display: grid; grid-template-columns: repeat(auto-fit, minmax(450px, 1fr)); gap: 20px; }
            .result-card { background: rgba(255, 255, 255, 0.9); border-radius: 15px; padding: 25px; box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1); transition: transform 0.3s ease; }
            .result-card:hover { transform: translateY(-3px); }
            .result-card.best { border: 2px solid #4CAF50; } .result-card.worst { border: 2px solid #f44336; }
            .result-header { display: flex; align-items: center; margin-bottom: 20px; }
            .result-icon { width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; margin-right: 12px; color: white; font-weight: bold; }
            .logo-ufpe { height: 150px; width: auto; }
            .result-icon.best { background: #4CAF50; } .result-icon.worst { background: #f44336; }
            .result-title { font-size: 1.2em; font-weight: 600; }
            .metrics-list { list-style: none; margin-bottom: 20px; }
            .metrics-list li { padding: 8px 0; border-bottom: 1px solid rgba(0, 0, 0, 0.05); display: flex; justify-content: space-between; align-items: center; }
            .metrics-list li:last-child { border-bottom: none; }
            .metric-name { font-weight: 500; color: #555; }
            .metric-val { font-weight: 600; }
            @keyframes fadeInUp { from { opacity: 0; transform: translateY(30px); } to { opacity: 1; transform: translateY(0); } }
            .stat-card, .kernels-section { animation: fadeInUp 0.6s ease forwards; }
        </style>
    </head>
    <body>
        <div class="dashboard-container">
            <div class="header">
                <img src="../../src/ufpe_logo.png" alt="Logotipo da UFPE" class="logo-ufpe">
                <h1>ELM - AvaliaÃ§Ã£o de ParÃ¢metros</h1>
                <p class="subtitle">
                    {% if is_classification %}
                        A acurÃ¡cia de teste Ã© a mÃ©trica de escolha para os resultados
                    {% else %}
                        O RMSE de teste Ã© a mÃ©trica de escolha para os resultados
                    {% endif %}
                </p>
            </div>

            <div class="stats-grid">
                <div class="stat-card best">
                    <div class="card-header"><div class="card-icon best">ğŸ†</div><div class="card-title">Melhor Desempenho Global</div></div>
                    <div class="metric-row"><span class="metric-label">ConfiguraÃ§Ã£o (n_hidden)</span><span class="metric-value best">{{ global_results.max.n_hidden }}</span></div>
                    <div class="metric-row"><span class="metric-label">Melhor AtivaÃ§Ã£o</span><span class="metric-value best">{{ global_results.max.act }}</span></div>
                    <div class="metric-row">
                        <span class="metric-label">
                            {% if is_classification %}AcurÃ¡cia de Treino{% else %}RMSE de Treino{% endif %}
                        </span>
                        <span class="metric-value best">
                            {{ "%.2f"|format(global_results.max.accuracy_train) }}{{ metric_unit }}
                            {% if global_results.max.std_train is not none and global_results.max.std_train > 0 %}
                                &plusmn; {{ "%.2f"|format(global_results.max.std_train) }}{{ metric_unit }}
                            {% endif %}
                        </span>
                    </div>
                    <div class="metric-row">
                        <span class="metric-label">
                            {% if is_classification %}AcurÃ¡cia de Teste{% else %}RMSE de Teste{% endif %}
                        </span>
                        <span class="metric-value best">
                            {{ "%.2f"|format(global_results.max.accuracy_test) }}{{ metric_unit }}
                            {% if global_results.max.std_test is not none and global_results.max.std_test > 0 %}
                                &plusmn; {{ "%.2f"|format(global_results.max.std_test) }}{{ metric_unit }}
                            {% endif %}
                        </span>
                    </div>
                    <div class="metric-row">
                        <span class="metric-label">Tempo de Treino</span>
                        <span class="metric-value best">
                            {{ "%.4f"|format(global_results.max.time_train) }}s
                            {% if global_results.max.std_time_train is not none and global_results.max.std_time_train > 0 %}
                                &plusmn; {{ "%.4f"|format(global_results.max.std_time_train) }}s
                            {% endif %}
                        </span>
                    </div>
                    <div class="metric-row">
                        <span class="metric-label">Tempo de Teste</span>
                        <span class="metric-value best">
                            {{ "%.4f"|format(global_results.max.time_test) }}s
                            {% if global_results.max.std_time_test is not none and global_results.max.std_time_test > 0 %}
                                &plusmn; {{ "%.4f"|format(global_results.max.std_time_test) }}s
                            {% endif %}
                        </span>
                    </div>
                    {% if is_classification and cm_global_best %}
                    <div class="cm-container">
                        <img class="cm-image" src="{{ cm_global_best }}" alt="Matriz de ConfusÃ£o - Melhor Global">
                    </div>
                    {% endif %}
                </div>

                <div class="stat-card worst">
                    <div class="card-header"><div class="card-icon worst">ğŸ’</div><div class="card-title">Pior Desempenho Global</div></div>
                    <div class="metric-row"><span class="metric-label">ConfiguraÃ§Ã£o (n_hidden)</span><span class="metric-value worst">{{ global_results.min.n_hidden }}</span></div>
                    <div class="metric-row"><span class="metric-label">Pior AtivaÃ§Ã£o</span><span class="metric-value worst">{{ global_results.min.act }}</span></div>
                    <div class="metric-row">
                        <span class="metric-label">
                            {% if is_classification %}AcurÃ¡cia de Treino{% else %}RMSE de Treino{% endif %}
                        </span>
                        <span class="metric-value worst">
                            {{ "%.2f"|format(global_results.min.accuracy_train) }}{{ metric_unit }}
                            {% if global_results.min.std_train is not none and global_results.min.std_train > 0 %}
                                &plusmn; {{ "%.2f"|format(global_results.min.std_train) }}{{ metric_unit }}
                            {% endif %}
                        </span>
                    </div>
                    <div class="metric-row">
                        <span class="metric-label">
                            {% if is_classification %}AcurÃ¡cia de Teste{% else %}RMSE de Teste{% endif %}
                        </span>
                        <span class="metric-value worst">
                            {{ "%.2f"|format(global_results.min.accuracy_test) }}{{ metric_unit }}
                            {% if global_results.min.std_test is not none and global_results.min.std_test > 0 %}
                                &plusmn; {{ "%.2f"|format(global_results.min.std_test) }}{{ metric_unit }}
                            {% endif %}
                        </span>
                    </div>
                    <div class="metric-row">
                        <span class="metric-label">Tempo de Treino</span>
                        <span class="metric-value worst">
                            {{ "%.4f"|format(global_results.min.time_train) }}s
                            {% if global_results.min.std_time_train is not none and global_results.min.std_time_train > 0 %}
                                &plusmn; {{ "%.4f"|format(global_results.min.std_time_train) }}s
                            {% endif %}
                        </span>
                    </div>
                    <div class="metric-row">
                        <span class="metric-label">Tempo de Teste</span>
                        <span class="metric-value worst">
                            {{ "%.4f"|format(global_results.min.time_test) }}s
                            {% if global_results.min.std_time_test is not none and global_results.min.std_time_test > 0 %}
                                &plusmn; {{ "%.4f"|format(global_results.min.std_time_test) }}s
                            {% endif %}
                        </span>
                    </div>
                    {% if is_classification and cm_global_worst %}
                    <div class="cm-container">
                        <img class="cm-image" src="{{ cm_global_worst }}" alt="Matriz de ConfusÃ£o - Pior Global">
                    </div>
                    {% endif %}
                </div>
            </div>

            <div class="kernels-section">
                <h2 class="section-title">Resumo por FunÃ§Ã£o de AtivaÃ§Ã£o</h2>
                {% for act_name, data in act_results.items() %}
                <div class="kernel-group">
                    <div class="kernel-title">FunÃ§Ã£o de AtivaÃ§Ã£o: {{ act_name }}</div>
                    <div class="kernel-results">
                        {% if data.max_test %}
                        <div class="result-card best">
                            <div class="result-header"><div class="result-icon best">ğŸ‘</div><div class="result-title">Melhor CenÃ¡rio</div></div>
                            <ul class="metrics-list">
                                <li><span class="metric-name">ConfiguraÃ§Ã£o (n_hidden):</span><span class="metric-val">{{ data.max_test.n_hidden }}</span></li>
                                <li>
                                    <span class="metric-name">
                                        {% if is_classification %}AcurÃ¡cia de Teste{% else %}RMSE de Teste{% endif %}
                                    </span>
                                    <span class="metric-val">
                                        {{ "%.2f"|format(data.max_test.accuracy_test) }}{{ metric_unit }}
                                        {% if data.max_test.std_test is not none and data.max_test.std_test > 0 %}
                                            &plusmn; {{ "%.2f"|format(data.max_test.std_test) }}{{ metric_unit }}
                                        {% endif %}
                                    </span>
                                </li>
                                <li><span class="metric-name">Tempo de Teste:</span><span class="metric-val">{{ "%.4f"|format(data.max_test.time_test) }}s{% if data.max_test.std_time_test is not none and data.max_test.std_time_test > 0 %} &plusmn; {{ "%.4f"|format(data.max_test.std_time_test) }}s{% endif %}</span></li>
                                <li>
                                    <span class="metric-name">
                                        {% if is_classification %}AcurÃ¡cia de Treino{% else %}RMSE de Treino{% endif %}
                                    </span>
                                    <span class="metric-val">
                                        {{ "%.2f"|format(data.max_test.accuracy_train) }}{{ metric_unit }}
                                        {% if data.max_test.std_train is not none and data.max_test.std_train > 0 %}
                                            &plusmn; {{ "%.2f"|format(data.max_test.std_train) }}{{ metric_unit }}
                                        {% endif %}
                                    </span>
                                </li>
                                <li><span class="metric-name">Tempo de Treino:</span><span class="metric-val">{{ "%.4f"|format(data.max_test.time_train) }}s{% if data.max_test.std_time_train is not none and data.max_test.std_time_train > 0 %} &plusmn; {{ "%.4f"|format(data.max_test.std_time_train) }}s{% endif %}</span></li>
                            </ul>
                            {% if is_classification and act_cm.get(act_name) and act_cm[act_name].best %}
                            <div class="cm-container"><img class="cm-image" src="{{ act_cm[act_name].best }}" alt="MC Melhor Teste {{ act_name }}"></div>
                            {% endif %}
                        </div>
                        {% endif %}

                        {% if data.min_test %}
                        <div class="result-card worst">
                            <div class="result-header"><div class="result-icon worst">ğŸ’</div><div class="result-title">Pior CenÃ¡rio</div></div>
                            <ul class="metrics-list">
                                <li><span class="metric-name">ConfiguraÃ§Ã£o (n_hidden):</span><span class="metric-val">{{ data.min_test.n_hidden }}</span></li>
                                <li>
                                    <span class="metric-name">
                                        {% if is_classification %}AcurÃ¡cia de Teste{% else %}RMSE de Teste{% endif %}
                                    </span>
                                    <span class="metric-val">
                                        {{ "%.2f"|format(data.min_test.accuracy_test) }}{{ metric_unit }}
                                        {% if data.min_test.std_test is not none and data.min_test.std_test > 0 %}
                                            &plusmn; {{ "%.2f"|format(data.min_test.std_test) }}{{ metric_unit }}
                                        {% endif %}
                                    </span>
                                </li>
                                <li><span class="metric-name">Tempo de Teste:</span><span class="metric-val">{{ "%.4f"|format(data.min_test.time_test) }}s{% if data.min_test.std_time_test is not none and data.min_test.std_time_test > 0 %} &plusmn; {{ "%.4f"|format(data.min_test.std_time_test) }}s{% endif %}</span></li>
                                <li>
                                    <span class="metric-name">
                                        {% if is_classification %}AcurÃ¡cia de Treino{% else %}RMSE de Treino{% endif %}
                                    </span>
                                    <span class="metric-val">
                                        {{ "%.2f"|format(data.min_test.accuracy_train) }}{{ metric_unit }}
                                        {% if data.min_test.std_train is not none and data.min_test.std_train > 0 %}
                                            &plusmn; {{ "%.2f"|format(data.min_test.std_train) }}{{ metric_unit }}
                                        {% endif %}
                                    </span>
                                </li>
                                <li><span class="metric-name">Tempo de Treino:</span><span class="metric-val">{{ "%.4f"|format(data.min_test.time_train) }}s{% if data.min_test.std_time_train is not none and data.min_test.std_time_train > 0 %} &plusmn; {{ "%.4f"|format(data.min_test.std_time_train) }}s{% endif %}</span></li>
                            </ul>
                            {% if is_classification and act_cm.get(act_name) and act_cm[act_name].worst %}
                            <div class="cm-container"><img class="cm-image" src="{{ act_cm[act_name].worst }}" alt="MC Pior Teste {{ act_name }}"></div>
                            {% endif %}
                        </div>
                        {% endif %}
                    </div>
                </div>
                {% endfor %}
            </div>
            
            {% if is_classification and diagnostics %}
            <div class="kernels-section" style="margin-top: 40px;">
                <h2 class="section-title">ğŸ” DiagnÃ³sticos AutomÃ¡ticos</h2>
                <p style="color: #666; margin-bottom: 30px; font-size: 1.1em;">
                    AnÃ¡lise detalhada do desempenho de cada kernel com recomendaÃ§Ãµes especÃ­ficas
                </p>
                
                {% for kernel_name, diagnosis in diagnostics.items() %}
                <div class="diagnosis-card status-{{ diagnosis.status }}" style="background: rgba(255, 255, 255, 0.95); border-radius: 15px; padding: 25px; margin-bottom: 20px; border-left: 5px solid 
                {% if diagnosis.status == 'critical' %}#dc3545
                {% elif diagnosis.status == 'unstable' or diagnosis.status == 'warning' or diagnosis.status == 'poor' %}#ffc107
                {% elif diagnosis.status == 'good' %}#28a745
                {% else %}#6c757d{% endif %};">
                    
                    <div style="display: flex; align-items: center; margin-bottom: 15px;">
                        <div style="font-size: 2em; margin-right: 15px;">
                            {% if diagnosis.status == 'critical' %}âŒ
                            {% elif diagnosis.status == 'unstable' or diagnosis.status == 'warning' or diagnosis.status == 'poor' %}âš ï¸
                            {% elif diagnosis.status == 'good' %}âœ…
                            {% else %}â“{% endif %}
                        </div>
                        <div>
                            <h3 style="margin: 0; font-size: 1.5em; color: #333;">{{ kernel_name }}</h3>
                            {% if diagnosis.problem %}
                            <p style="margin: 5px 0 0 0; color: #666; font-weight: 500;">{{ diagnosis.problem }}</p>
                            {% endif %}
                        </div>
                    </div>
                    
                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin-bottom: 15px;">
                        <strong style="color: #555;">ğŸ“ ExplicaÃ§Ã£o:</strong>
                        <p style="margin: 10px 0 0 0; line-height: 1.6; color: #666;">{{ diagnosis.explanation }}</p>
                    </div>
                    
                    <div style="background: {% if diagnosis.status == 'good' %}#d4edda{% else %}#fff3cd{% endif %}; padding: 15px; border-radius: 8px; border-left: 3px solid {% if diagnosis.status == 'good' %}#28a745{% else %}#ffc107{% endif %};">
                        <strong style="color: #555;">ğŸ’¡ RecomendaÃ§Ã£o:</strong>
                        <p style="margin: 10px 0 0 0; line-height: 1.6; color: #666;">{{ diagnosis.recommendation }}</p>
                    </div>
                </div>
                {% endfor %}
            </div>
            {% endif %}
        </div>
    </body>
    </html>
    """

    template = Template(html_template)
    rendered = template.render(
        global_results=global_results,
        act_results=act_results,
        is_classification=is_classification,
        metric_label=metric_label,
        metric_unit=metric_unit,
        cm_global_best=cm_global_best,
        cm_global_worst=cm_global_worst,
        act_cm=act_cm,
        diagnostics=diagnostics if diagnostics else {},
    )

    output_path = os.path.join(script_dir, output_file)
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(rendered)

    print(f"RelatÃ³rio HTML gerado: {output_path}")


#========================================================================
# INTERFACE DE LINHA DE COMANDO (CLI)
#========================================================================

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description='mELM - MÃ¡quina de Aprendizado Extremo MorfolÃ³gico para DetecÃ§Ã£o de Malware',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos:
  # ValidaÃ§Ã£o cruzada K-fold com kernels morfolÃ³gicos
  python melmParameters_complete.py -tall dataset.csv -ty 1 -nh 100 -af erosion,dilation -kfold 10 -v
  
  # Treino/teste separados com normalizaÃ§Ã£o virusNorm
  python melmParameters_complete.py -tr train.csv -ts test.csv -ty 1 -virusNorm -nh 100 -af dilation -v
  
  # Testar todos os kernels com mÃºltiplas contagens de neurÃ´nios
  python melmParameters_complete.py -tall malware.csv -ty 1 -nh 50,100,200 -af all -kfold 5 -v
  
  # Tarefa de regressÃ£o
  python melmParameters_complete.py -tr train.csv -ts test.csv -ty 0 -nh 100 -af linear -v

FunÃ§Ãµes de AtivaÃ§Ã£o:
  Tradicionais: linear, sig, sin, hardlim, tribas, radbas
  MorfolÃ³gicas: erosion, dilation, fuzzy-erosion, fuzzy-dilation, bitwise-erosion, bitwise-dilation
  Use 'all' para testar todas as funÃ§Ãµes
        """
    )
    
    # OpÃ§Ãµes de entrada de dados (modos mutuamente exclusivos)
    data_group = parser.add_argument_group('Entrada de Dados (escolha um modo)')
    data_group.add_argument('-tall', '--AllData_File', dest='AllData_File', action='store',
                           help='Arquivo com todos os dados para validaÃ§Ã£o cruzada K-fold')
    data_group.add_argument('-tr', '--TrainingData_File', dest='TrainingData_File', action='store',
                           help='Arquivo de dados de treinamento (use com -ts)')
    data_group.add_argument('-ts', '--TestingData_File', dest='TestingData_File', action='store',
                           help='Arquivo de dados de teste (use com -tr)')
    
    # ConfiguraÃ§Ã£o do modelo
    config_group = parser.add_argument_group('ConfiguraÃ§Ã£o do Modelo')
    config_group.add_argument('-ty', '--Elm_Type', dest='Elm_Type', action='store', required=True,
                             help='Tipo de tarefa: 0=regressÃ£o, 1=classificaÃ§Ã£o')
    config_group.add_argument('-nh', '--nHiddenNeurons', dest='nHiddenNeurons', action='store', required=True,
                             help="NÃºmero de neurÃ´nios ocultos (lista separada por vÃ­rgula, ex: '50,100,200')")
    config_group.add_argument('-af', '--ActivationFunction', dest='ActivationFunction', action='store', required=True,
                             help="FunÃ§Ã£o de ativaÃ§Ã£o (lista separada por vÃ­rgula ou 'all')")
    
    # ParÃ¢metros opcionais
    optional_group = parser.add_argument_group('ParÃ¢metros Opcionais')
    optional_group.add_argument('-virusNorm', dest='virusNorm', action='store_true',
                               help='Aplica normalizaÃ§Ã£o virusNorm [0.1, 0.9] para caracterÃ­sticas de malware')
    optional_group.add_argument('-kfold', dest='kfold', action='store', type=int, default=5,
                               help='NÃºmero de folds para validaÃ§Ã£o cruzada (padrÃ£o: 5)')
    optional_group.add_argument(
        '-sep',
        dest='sep',
        action='store',
        default=None,
        help=(
            "Separador do CSV. Exemplos:\n"
            "  -sep \",\"   (vÃ­rgula)\n"
            "  -sep \";\"   (ponto e vÃ­rgula)\n"
            "  -sep tab    (TAB)\n"
            "  -sep pipe   (|)\n"
            "  -sep auto   (padrÃ£o â€” autodetecta entre ',', ';', TAB, '|', ':', '^', '~', ' ')"
        )
    )
    optional_group.add_argument('-sd', '--seed', dest='nSeed', action='store', type=int,
                               help='Semente aleatÃ³ria para reprodutibilidade')
    optional_group.add_argument('-v', '--verbose', dest='verbose', action='store_true',
                               help='Ativa saÃ­da detalhada (verbose)')
    
    args = parser.parse_args()
    
    # Valida modos de entrada
    has_separate = args.TrainingData_File and args.TestingData_File
    has_all = args.AllData_File
    
    if not has_separate and not has_all:
        parser.error("Deve especificar (-tr e -ts) ou -tall")
    
    if has_separate and has_all:
        parser.error("NÃ£o Ã© possÃ­vel usar (-tr/-ts) e -tall simultaneamente")
    
    if has_separate and (not args.TrainingData_File or not args.TestingData_File):
        parser.error("Ambos -tr e -ts devem ser especificados juntos")
    
    # Executa mELM
    try:
        ff = melm()
        ff.main(
            args.TrainingData_File,
            args.TestingData_File,
            args.AllData_File,
            args.Elm_Type,
            args.nHiddenNeurons,
            args.ActivationFunction,
            args.nSeed,
            args.kfold,
            args.sep,
            args.verbose,
            args.virusNorm
        )
    except Exception as e:
        print(f"\nâœ— Erro durante execuÃ§Ã£o: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)