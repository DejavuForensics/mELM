ğŸ”¹ 1. ExecuÃ§Ã£o simples (treino/teste separados, sem busca/KFold)
Se vocÃª tem arquivos treino e teste jÃ¡ separados:
python melmParameters.py -tr treino.csv -ts teste.csv -ty 1 -nh 100 -af sigmoid
    â€¢ -ty 1 â†’ classificaÃ§Ã£o (use 0 para regressÃ£o)
    â€¢ -nh â†’ nÃºmero de neurÃ´nios ocultos (aqui 100)
    â€¢ -af â†’ funÃ§Ã£o de ativaÃ§Ã£o (sigmoid, linear, radbas, etc.)

ğŸ”¹ 2. ExecuÃ§Ã£o com AllData_File + KFold + busca
ğŸ‘‰ Este Ã© o caminho que gera o elm_report.html com Melhor/Pior desempenho.

python melmParameters.py -tall dados.csv -ty 1 -nh 50,100,200 -af sigmoid,linear,radbas -kfold 10

    â€¢ -tall dados.csv â†’ arquivo Ãºnico (com todas as amostras)
    â€¢ -ty 1 â†’ classificaÃ§Ã£o (0 para regressÃ£o)
    â€¢ -nh 50,100,200 â†’ vai testar 3 valores de neurÃ´nios ocultos
    â€¢ -af sigmoid,linear,radbas â†’ vai testar 3 ativaÃ§Ãµes diferentes
    â€¢ -kfold 10 â†’ validaÃ§Ã£o cruzada 10-fold (com shuffle)
SaÃ­da esperada:
    â€¢ Prints no terminal com melhores/piores resultados
    â€¢ Arquivo elm_report.html + imagens em elm_report_images/

ğŸ”¹ 3. Exemplo mÃ­nimo sÃ³ com busca em duas ativaÃ§Ãµes
python melmParameters.py -tall dataset.csv -ty 1 -nh 100 -af sigmoid,radbas -kfold 5
Esse comando:
    â€¢ Testa sigmoid e radbas com 100 neurÃ´nios,
    â€¢ Faz 5-fold CV,
    â€¢ Escolhe melhor/pior por acurÃ¡cia de teste,
    â€¢ Salva relatÃ³rio em elm_report.html.

